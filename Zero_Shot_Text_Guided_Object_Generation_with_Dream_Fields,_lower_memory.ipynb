{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pollinations/hive/blob/main/Zero_Shot_Text_Guided_Object_Generation_with_Dream_Fields%2C_lower_memory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0PbNr1Ncxmw"
      },
      "source": [
        "# Zero-Shot Text-Guided Object Generation with Dream Fields\n",
        "**By [Ajay Jain](https://ajayj.com/), [Ben Mildenhall](https://bmild.github.io/), [Jonathan T. Barron](https://jonbarron.info/), [Pieter Abbeel](https://people.eecs.berkeley.edu/~pabbeel/), and [Ben Poole](https://cs.stanford.edu/~poole/).**\n",
        "\n",
        "\n",
        "Website: https://ajayj.com/dreamfields\n",
        "\n",
        "This notebook demonstrates a scaled down version of Dream Fields, a method for synthesizing 3D objects from natural language descriptions. Dream Fields train a 3D Neural Radiance Field (NeRF) so 2D renderings from any perspective are semantically consistent with a given description. Our loss is based on the OpenAI CLIP text-image model.\n",
        "\n",
        "If you find this code relevant to your work, please cite our [paper](https://arxiv.org/abs/2112.01455):\n",
        "```\n",
        "@article{jain2021dreamfields,\n",
        "  author = {Jain, Ajay and Mildenhall, Ben and Barron, Jonathan T. and Abbeel, Pieter and Poole, Ben},\n",
        "  title = {Zero-Shot Text-Guided Object Generation with Dream Fields},\n",
        "  joural = {arXiv},\n",
        "  month = {December},\n",
        "  year = {2021},\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip\n",
        "#!pip install --upgrade jax[cuda] jaxlib -f https://storage.googleapis.com/jax-releases/jax_releases.html\n",
        "!python -c \"print(__import__('jax').local_devices())\"\n"
      ],
      "metadata": {
        "id": "xHocyi1uB3Yz",
        "outputId": "b4243c01-e08f-44d9-f6de-c9939c033db4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.1.3)\n",
            "Collecting pip\n",
            "  Downloading pip-22.0.3-py3-none-any.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 5.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 21.1.3\n",
            "    Uninstalling pip-21.1.3:\n",
            "      Successfully uninstalled pip-21.1.3\n",
            "Successfully installed pip-22.0.3\n",
            "[GpuDevice(id=0, process_index=0)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/google-research/google-research\n",
        "%cd google-research/dreamfields\n",
        "#!pip install -r requirements.txt\n",
        "!pip install clu\n",
        "!pip install git+git://github.com/voodoohop/scenic.git\n",
        "!pip install git+https://github.com/openai/CLIP.git\n",
        "!pip install dm_pix mediapy\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.config.experimental.set_visible_devices([], 'GPU')\n"
      ],
      "metadata": {
        "id": "-66Qid-BCkpe",
        "outputId": "46010406-ebdb-4a20-8384-4200ad80e9a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'google-research'...\n",
            "remote: Enumerating objects: 47895, done.\u001b[K\n",
            "remote: Counting objects: 100% (7984/7984), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6061/6061), done.\u001b[K\n",
            "remote: Total 47895 (delta 1890), reused 7743 (delta 1852), pack-reused 39911\u001b[K\n",
            "Receiving objects: 100% (47895/47895), 326.75 MiB | 35.84 MiB/s, done.\n",
            "Resolving deltas: 100% (23798/23798), done.\n",
            "Checking out files: 100% (13562/13562), done.\n",
            "/content/google-research/dreamfields\n",
            "Collecting clu\n",
            "  Downloading clu-0.0.6-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 KB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from clu) (2.8.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from clu) (1.0.0)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.7/dist-packages (from clu) (0.2.25)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.7/dist-packages (from clu) (0.1.71+cuda111)\n",
            "Collecting flax\n",
            "  Downloading flax-0.4.0-py3-none-any.whl (176 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.7/176.7 KB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from clu) (4.0.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from clu) (21.3)\n",
            "Collecting ml-collections\n",
            "  Downloading ml_collections-0.1.1.tar.gz (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 KB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from clu) (1.21.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py->clu) (1.15.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from flax->clu) (3.2.2)\n",
            "Collecting optax\n",
            "  Downloading optax-0.1.1-py3-none-any.whl (136 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m136.3/136.3 KB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: msgpack in /usr/local/lib/python3.7/dist-packages (from flax->clu) (1.0.3)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.7/dist-packages (from jax->clu) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jax->clu) (3.10.0.2)\n",
            "Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from jax->clu) (1.4.1)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from jaxlib->clu) (2.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from ml-collections->clu) (3.13)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from ml-collections->clu) (0.5.5)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->clu) (3.0.7)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->clu) (1.6.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow->clu) (57.4.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->clu) (0.5.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->clu) (1.43.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->clu) (13.0.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->clu) (1.1.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->clu) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->clu) (0.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->clu) (1.13.3)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->clu) (2.8.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->clu) (3.1.0)\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.5/462.5 KB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->clu) (0.24.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->clu) (3.17.3)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow->clu) (2.8.0)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->clu) (21.4.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->clu) (0.16.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->clu) (0.3.4)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->clu) (1.6.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->clu) (2.23.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->clu) (0.1.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->clu) (4.62.3)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->clu) (2.3)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->clu) (5.4.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow->clu) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow->clu) (1.5.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow-datasets->clu) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow-datasets->clu) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow-datasets->clu) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow-datasets->clu) (1.24.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->clu) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->clu) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->clu) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->clu) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->clu) (1.35.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->clu) (1.0.1)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources->tensorflow-datasets->clu) (3.7.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flax->clu) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flax->clu) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flax->clu) (2.8.2)\n",
            "Collecting chex>=0.0.4\n",
            "  Downloading chex-0.1.0-py3-none-any.whl (65 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.1/65.1 KB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-metadata->tensorflow-datasets->clu) (1.54.0)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.4->optax->flax->clu) (0.11.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->clu) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->clu) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->clu) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->clu) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->clu) (4.11.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->clu) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->clu) (3.2.0)\n",
            "Building wheels for collected packages: ml-collections\n",
            "  Building wheel for ml-collections (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ml-collections: filename=ml_collections-0.1.1-py3-none-any.whl size=94524 sha256=f91609c0e88abf9e021ed1ff54d7ee0b188c73ed4cabaf75631f135de60314de\n",
            "  Stored in directory: /root/.cache/pip/wheels/b7/da/64/33c926a1b10ff19791081b705879561b715a8341a856a3bbd2\n",
            "Successfully built ml-collections\n",
            "Installing collected packages: tf-estimator-nightly, ml-collections, chex, optax, flax, clu\n",
            "Successfully installed chex-0.1.0 clu-0.0.6 flax-0.4.0 ml-collections-0.1.1 optax-0.1.1 tf-estimator-nightly-2.8.0.dev2021122109\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting git+git://github.com/voodoohop/scenic.git\n",
            "  Cloning git://github.com/voodoohop/scenic.git to /tmp/pip-req-build-lhwnnk30\n",
            "  Running command git clone --filter=blob:none --quiet git://github.com/voodoohop/scenic.git /tmp/pip-req-build-lhwnnk30\n",
            "  Resolved git://github.com/voodoohop/scenic.git to commit fcc03f530155c52f3af2bff702d1b744a35b341d\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from scenic==0.0.1) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.12 in /usr/local/lib/python3.7/dist-packages (from scenic==0.0.1) (1.21.5)\n",
            "Requirement already satisfied: ml-collections>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from scenic==0.0.1) (0.1.1)\n",
            "Collecting tensorflow<2.8,>=2.7.0\n",
            "  Downloading tensorflow-2.7.1-cp37-cp37m-manylinux2010_x86_64.whl (495.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m495.0/495.0 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-addons>=0.15.0\n",
            "  Downloading tensorflow_addons-0.16.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting immutabledict>=2.2.1\n",
            "  Downloading immutabledict-2.2.1-py3-none-any.whl (4.0 kB)\n",
            "Requirement already satisfied: clu>=0.0.6 in /usr/local/lib/python3.7/dist-packages (from scenic==0.0.1) (0.0.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=1.0.0->scenic==0.0.1) (1.15.0)\n",
            "Requirement already satisfied: flax in /usr/local/lib/python3.7/dist-packages (from clu>=0.0.6->scenic==0.0.1) (0.4.0)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.7/dist-packages (from clu>=0.0.6->scenic==0.0.1) (0.1.71+cuda111)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.7/dist-packages (from clu>=0.0.6->scenic==0.0.1) (0.2.25)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from clu>=0.0.6->scenic==0.0.1) (21.3)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from clu>=0.0.6->scenic==0.0.1) (4.0.1)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from ml-collections>=0.1.1->scenic==0.0.1) (0.5.5)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from ml-collections>=0.1.1->scenic==0.0.1) (3.13)\n",
            "Collecting gast<0.5.0,>=0.2.1\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->scenic==0.0.1) (1.43.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->scenic==0.0.1) (3.17.3)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->scenic==0.0.1) (1.13.3)\n",
            "Collecting tensorflow-estimator<2.8,~=2.7.0rc0\n",
            "  Downloading tensorflow_estimator-2.7.0-py2.py3-none-any.whl (463 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m463.1/463.1 KB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->scenic==0.0.1) (0.24.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->scenic==0.0.1) (1.6.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->scenic==0.0.1) (1.1.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->scenic==0.0.1) (3.3.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->scenic==0.0.1) (0.2.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->scenic==0.0.1) (0.37.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->scenic==0.0.1) (3.10.0.2)\n",
            "Collecting keras<2.8,>=2.7.0rc0\n",
            "  Downloading keras-2.7.0-py2.py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->scenic==0.0.1) (13.0.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->scenic==0.0.1) (1.1.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->scenic==0.0.1) (3.1.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->scenic==0.0.1) (2.8.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->scenic==0.0.1) (2.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons>=0.15.0->scenic==0.0.1) (2.7.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow<2.8,>=2.7.0->scenic==0.0.1) (1.5.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->scenic==0.0.1) (3.3.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->scenic==0.0.1) (1.35.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->scenic==0.0.1) (2.23.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->scenic==0.0.1) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->scenic==0.0.1) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->scenic==0.0.1) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->scenic==0.0.1) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->scenic==0.0.1) (0.4.6)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.7/dist-packages (from flax->clu>=0.0.6->scenic==0.0.1) (1.0.3)\n",
            "Requirement already satisfied: optax in /usr/local/lib/python3.7/dist-packages (from flax->clu>=0.0.6->scenic==0.0.1) (0.1.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from flax->clu>=0.0.6->scenic==0.0.1) (3.2.2)\n",
            "Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from jax->clu>=0.0.6->scenic==0.0.1) (1.4.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->clu>=0.0.6->scenic==0.0.1) (3.0.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->clu>=0.0.6->scenic==0.0.1) (4.62.3)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->clu>=0.0.6->scenic==0.0.1) (5.4.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->clu>=0.0.6->scenic==0.0.1) (0.16.0)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->clu>=0.0.6->scenic==0.0.1) (21.4.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->clu>=0.0.6->scenic==0.0.1) (0.1.6)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->clu>=0.0.6->scenic==0.0.1) (0.3.4)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->clu>=0.0.6->scenic==0.0.1) (2.3)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->clu>=0.0.6->scenic==0.0.1) (1.6.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->scenic==0.0.1) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->scenic==0.0.1) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->scenic==0.0.1) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->scenic==0.0.1) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->scenic==0.0.1) (4.11.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->scenic==0.0.1) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->scenic==0.0.1) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->scenic==0.0.1) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->scenic==0.0.1) (3.0.4)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources->tensorflow-datasets->clu>=0.0.6->scenic==0.0.1) (3.7.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flax->clu>=0.0.6->scenic==0.0.1) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flax->clu>=0.0.6->scenic==0.0.1) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flax->clu>=0.0.6->scenic==0.0.1) (0.11.0)\n",
            "Requirement already satisfied: chex>=0.0.4 in /usr/local/lib/python3.7/dist-packages (from optax->flax->clu>=0.0.6->scenic==0.0.1) (0.1.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-metadata->tensorflow-datasets->clu>=0.0.6->scenic==0.0.1) (1.54.0)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.4->optax->flax->clu>=0.0.6->scenic==0.0.1) (0.11.2)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->scenic==0.0.1) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->scenic==0.0.1) (3.2.0)\n",
            "Building wheels for collected packages: scenic\n",
            "  Building wheel for scenic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scenic: filename=scenic-0.0.1-py3-none-any.whl size=10026364 sha256=d8d6f2278cd878235932339e170415ddebb47d59d2f4134bfb3d2f40be5a22fe\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-abgyxufi/wheels/c1/a0/9d/fbfedf1913f906f783c3ef5bebd886cc56342829b42b1a25aa\n",
            "Successfully built scenic\n",
            "Installing collected packages: tensorflow-estimator, keras, tensorflow-addons, immutabledict, gast, tensorflow, scenic\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.8.0\n",
            "    Uninstalling keras-2.8.0:\n",
            "      Successfully uninstalled keras-2.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.0\n",
            "    Uninstalling tensorflow-2.8.0:\n",
            "      Successfully uninstalled tensorflow-2.8.0\n",
            "Successfully installed gast-0.4.0 immutabledict-2.2.1 keras-2.7.0 scenic-0.0.1 tensorflow-2.7.1 tensorflow-addons-0.16.1 tensorflow-estimator-2.7.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting git+https://github.com/openai/CLIP.git\n",
            "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-onqswm71\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-onqswm71\n",
            "  Resolved https://github.com/openai/CLIP.git to commit 40f5484c1c74edd83cb9cf687c6ab92b28d8b656\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ftfy\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 KB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (2019.12.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (4.62.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (0.11.1+cu111)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from ftfy->clip==1.0) (0.2.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->clip==1.0) (3.10.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->clip==1.0) (1.21.5)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->clip==1.0) (7.1.2)\n",
            "Building wheels for collected packages: clip\n",
            "  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369221 sha256=e4c4846a3de96340fd9a8a3625e57215ba5d9c09af267e68967453173118846a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-hpqv90it/wheels/fd/b9/c3/5b4470e35ed76e174bff77c92f91da82098d5e35fd5bc8cdac\n",
            "Successfully built clip\n",
            "Installing collected packages: ftfy, clip\n",
            "Successfully installed clip-1.0 ftfy-6.1.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting dm_pix\n",
            "  Downloading dm_pix-0.3.0-py3-none-any.whl (36 kB)\n",
            "Collecting mediapy\n",
            "  Downloading mediapy-1.0.3-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: chex>=0.0.6 in /usr/local/lib/python3.7/dist-packages (from dm_pix) (0.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mediapy) (1.21.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from mediapy) (7.1.2)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from mediapy) (5.5.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mediapy) (3.2.2)\n",
            "Requirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.6->dm_pix) (0.1.6)\n",
            "Requirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.6->dm_pix) (0.1.71+cuda111)\n",
            "Requirement already satisfied: jax>=0.1.55 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.6->dm_pix) (0.2.25)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.6->dm_pix) (0.11.2)\n",
            "Requirement already satisfied: absl-py>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.6->dm_pix) (1.0.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->mediapy) (57.4.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->mediapy) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->mediapy) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->mediapy) (5.1.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->mediapy) (4.8.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->mediapy) (0.8.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->mediapy) (2.6.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->mediapy) (1.0.18)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapy) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapy) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapy) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapy) (3.0.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.9.0->chex>=0.0.6->dm_pix) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jax>=0.1.55->chex>=0.0.6->dm_pix) (3.10.0.2)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.7/dist-packages (from jax>=0.1.55->chex>=0.0.6->dm_pix) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from jax>=0.1.55->chex>=0.0.6->dm_pix) (1.4.1)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from jaxlib>=0.1.37->chex>=0.0.6->dm_pix) (2.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->mediapy) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->mediapy) (0.7.0)\n",
            "Installing collected packages: mediapy, dm_pix\n",
            "Successfully installed dm_pix-0.3.0 mediapy-1.0.3\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd\n",
        "%cd /content/google-research/dreamfields/\n",
        "\n",
        "#import os \n",
        "#os.environ['LD_LIBRARY_PATH']='/usr/local/cuda-11.1/lib64:/usr/lib64-nvidia'\n",
        "!python run.py --config=dreamfields/config/config_lq.py --query=\"sleepy bonsai cat\""
      ],
      "metadata": {
        "id": "PGNOiEPNDXET",
        "outputId": "1b14b804-8808-4595-bc02-ac6fd4eed003",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/google-research/dreamfields\n",
            "/content/google-research/dreamfields\n",
            "/usr/local/lib/python3.7/dist-packages/jax/_src/lib/xla_bridge.py:400: UserWarning: jax.host_id has been renamed to jax.process_index. This alias will eventually be removed; please update your code.\n",
            "  \"jax.host_id has been renamed to jax.process_index. This alias \"\n",
            "I0220 16:33:06.889394 139677965760384 xla_bridge.py:231] Unable to initialize backend 'tpu_driver': NOT_FOUND: Unable to find driver in registry given worker: \n",
            "I0220 16:33:07.135651 139677965760384 xla_bridge.py:231] Unable to initialize backend 'tpu': INVALID_ARGUMENT: TpuPlatform is not available.\n",
            "/usr/local/lib/python3.7/dist-packages/jax/_src/lib/xla_bridge.py:413: UserWarning: jax.host_count has been renamed to jax.process_count. This alias will eventually be removed; please update your code.\n",
            "  \"jax.host_count has been renamed to jax.process_count. This alias \"\n",
            "I0220 16:33:07.136054 139677965760384 run.py:65] JAX host: 0 / 1\n",
            "I0220 16:33:07.136272 139677965760384 run.py:66] JAX devices: [GpuDevice(id=0, process_index=0)]\n",
            "I0220 16:33:07.136655 139677965760384 local.py:45] Setting task status: host_id: 0, host_count: 1\n",
            "I0220 16:33:07.136985 139677965760384 local.py:51] Created artifact experiment_dir of type ArtifactType.DIRECTORY and value results.\n",
            "I0220 16:33:07.137139 139677965760384 local.py:51] Created artifact work_unit_dir of type ArtifactType.DIRECTORY and value results/'sleepy bonsai cat' 20220220-163307.\n",
            "I0220 16:33:07.137219 139677965760384 run.py:94] experiment_dir=results work_unit_dir=results/'sleepy bonsai cat' 20220220-163307\n",
            "I0220 16:33:09.018795 139677965760384 run.py:109] config={\n",
            "    \"acc_lam\": 0.5,\n",
            "    \"acc_lam_after\": 0,\n",
            "    \"acc_target0\": 0.5,\n",
            "    \"acc_target1\": 0.1,\n",
            "    \"acc_target_i_split\": 500,\n",
            "    \"adam_eps\": 1e-05,\n",
            "    \"augment_backgrounds\": true,\n",
            "    \"beta_after\": 20000,\n",
            "    \"bg_blur_std_range\": [\n",
            "        0.0,\n",
            "        10.0\n",
            "    ],\n",
            "    \"checker_bg_nsq\": 8,\n",
            "    \"checker_bg_prob\": 0.333,\n",
            "    \"checkpoint_every\": 1000,\n",
            "    \"clip_width\": 224,\n",
            "    \"crop_width\": 80,\n",
            "    \"defragment_every\": 200,\n",
            "    \"ema_scene_origin\": true,\n",
            "    \"far\": 5.732050807568877,\n",
            "    \"features_early\": [\n",
            "        128\n",
            "    ],\n",
            "    \"features_late\": [\n",
            "        128,\n",
            "        4\n",
            "    ],\n",
            "    \"features_residual\": [\n",
            "        [\n",
            "            256,\n",
            "            128\n",
            "        ],\n",
            "        [\n",
            "            256,\n",
            "            128\n",
            "        ],\n",
            "        [\n",
            "            256,\n",
            "            128\n",
            "        ],\n",
            "        [\n",
            "            256,\n",
            "            128\n",
            "        ]\n",
            "    ],\n",
            "    \"fft_bg_prob\": 0.334,\n",
            "    \"flush_every\": 500,\n",
            "    \"focal_mult_range\": [\n",
            "        1.2,\n",
            "        1.2\n",
            "    ],\n",
            "    \"fourfeat\": true,\n",
            "    \"hq_video_every\": 10000,\n",
            "    \"iters\": 10000,\n",
            "    \"jitter\": true,\n",
            "    \"keep_every_n_steps\": 10000,\n",
            "    \"log_scalars_every\": 50,\n",
            "    \"loss_model\": \"clip_vit_b16\",\n",
            "    \"lr0\": 1e-05,\n",
            "    \"lr1\": 0.0001,\n",
            "    \"lr2\": 0.0001,\n",
            "    \"lr_cosine_decay\": false,\n",
            "    \"lr_i_split\": 1500,\n",
            "    \"min_aug_acc\": 0.0,\n",
            "    \"mipnerf\": {\n",
            "        \"decay_iters\": 1000,\n",
            "        \"decay_start\": 1.0,\n",
            "        \"sigma_activation\": \"softplus\",\n",
            "        \"use_cov\": true\n",
            "    },\n",
            "    \"mlp_activation\": \"swish\",\n",
            "    \"mr0\": 1.0,\n",
            "    \"mr1\": 1.0,\n",
            "    \"mr_i_split\": 10000,\n",
            "    \"mr_norm\": \"inf\",\n",
            "    \"n_local_aug\": 8,\n",
            "    \"near\": 2.267949192431123,\n",
            "    \"noise_bg_prob\": 0.333,\n",
            "    \"num_samples\": 192,\n",
            "    \"parameterization\": \"mipnerf\",\n",
            "    \"phi_range\": [\n",
            "        -30,\n",
            "        -30\n",
            "    ],\n",
            "    \"posenc_deg\": 8,\n",
            "    \"posenc_dirs_deg\": 4,\n",
            "    \"queries_r\": [\n",
            "        \"a blue bicycle parked by a metal gate.\",\n",
            "        \"an orange bike leaning on a pole in the snow.\",\n",
            "        \"there are some colored lights hanging from street lamps.\",\n",
            "        \"the apple symbol is show on the premacy car.\",\n",
            "        \"an orange motorcycle is shown at close range.\",\n",
            "        \"a blue motorbike has a \\\"minnesota\\\" license plate.\",\n",
            "        \"the side of an american aircraft showing the door.\",\n",
            "        \"a floor drain is set in concrete with an advisory not to step on it.\",\n",
            "        \"a bus covered with assorted colorful graffiti on the side of it.\",\n",
            "        \"a bus covered in graffiti is stationary on the pavement.\",\n",
            "        \"a bike image on some double doors with windows.\",\n",
            "        \"a red train cart is shown at close range.\",\n",
            "        \"a truck is drying several items of clothing in the sun.\",\n",
            "        \"the rotted out bed of a truck left in the woods.\",\n",
            "        \"a boat on the water tied down to a stake.\",\n",
            "        \"an inflatable raft that has its top open.\",\n",
            "        \"a red light in front of a tall building.\",\n",
            "        \"a street sign says walk and don't walk.\",\n",
            "        \"a red and blue fire hydrant with flowers around it.\",\n",
            "        \"a red fire hydrant with an open sign on it.\",\n",
            "        \"a street sign with stickers on the back of it.\",\n",
            "        \"a red stop sign with lots of writing all over it.\",\n",
            "        \"a parking meter with a time expired label on it.\",\n",
            "        \"a blue faced machine for printing parking passes.\",\n",
            "        \"a bag full of trash sitting on a old park bench.\",\n",
            "        \"a park bench sits under a tree with the sun shining.\",\n",
            "        \"a picture of a flamingo scratching its neck.\",\n",
            "        \"a large blue bird standing next to a painting of flowers.\",\n",
            "        \"a cat is staring ahead as the back another cat's head is seen in front of him.\",\n",
            "        \"an orange cat looking upside down through glasses.\",\n",
            "        \"a bulldog is wearing a black pirate hat.\",\n",
            "        \"a dog standing at a gate wanting to get out of the fence.\",\n",
            "        \"a brown and white horse wearning a harness eating some hay.\",\n",
            "        \"a brown and white horse is wearing a blue muzzle.\",\n",
            "        \"a sheep standing in the grass with something on its ears.\",\n",
            "        \"a sheep looking through the slats of a wired fence.\",\n",
            "        \"a black cow looks directly at the camera.\",\n",
            "        \"a horned cow  standing in a green grass field.\",\n",
            "        \"an elephant with trimmed tusks relaxing with a covering of hay on its back.\",\n",
            "        \"an elephant placing some leaves in its mouth with its trunk.\",\n",
            "        \"the polar bear swimming briskly through the ocean current.\",\n",
            "        \"a large black bear is facing straight ahead.\",\n",
            "        \"the painting is of a zebra in a cage.\",\n",
            "        \"a zebra is eating grass on the ground.\",\n",
            "        \"a giraffe leaning it's long neck over the fence to eat leaves off a bush.\",\n",
            "        \"a very big giraffe that is siting on the ground.\",\n",
            "        \"a stuffed animal in a bag in a room.\",\n",
            "        \"a large umbrella open wide on a pole.\",\n",
            "        \"the plants can be seen through the orange mesh.\",\n",
            "        \"a fireplace mantle that has been faced in a light stone.\",\n",
            "        \"a tan table top hosts a pen and a necktie.\",\n",
            "        \"a gold tie is tied under a brown dress shirt with stripes.\",\n",
            "        \"a piece of gray luggage with travel stickers.\",\n",
            "        \"a cat relaxes in a suitcase next to a pile of clothes.\",\n",
            "        \"a yellow frisbee next to a box with nike cleats.\",\n",
            "        \"blue frisbee and envelope it was shipped in.\",\n",
            "        \"a large pair of skis rests against a wall.\",\n",
            "        \"appears to be some old skis propped up against a stone memorial.\",\n",
            "        \"a snowboard standing upright in a snow bank.\",\n",
            "        \"a snowboard and gloves laying in the snow.\",\n",
            "        \"a blue and white traffic sign on a grey brick wall.\",\n",
            "        \"a cat shaped kite sits in the grass.\",\n",
            "        \"there is a very colorful kite that is in the air.\",\n",
            "        \"a bat and shin guard in the closet.\",\n",
            "        \"a baseball bat with a batting helmet upsidedown.\",\n",
            "        \"a stuffed animal that is frowning is on a skateboard.\",\n",
            "        \"an very well used upside down skateboard on grass.\",\n",
            "        \"white surfboard leaning against a brown tiki wall.\",\n",
            "        \"a small surfboard sign that says trader vic's, los angeles.\",\n",
            "        \"a couple of snowmen have been built in suburban backyards after a recently fallen snow.\",\n",
            "        \"very large tennis racket with hello kitty on it.\",\n",
            "        \"a blender and jar of red liquid on a table.\",\n",
            "        \"a plastic jar of honey glowing in the middle of the dark.\",\n",
            "        \"a table with a blender and a glass on it.\",\n",
            "        \"a glass of wine sitting on the top of a swimming pool side.\",\n",
            "        \"a glass measuring cup with yellow liquid in it.\",\n",
            "        \"a blender full of liquid is spilling everywhere.\",\n",
            "        \"a dish of food topped with sour cream and a fork.\",\n",
            "        \"a pizza and fork on a tray on the table.\",\n",
            "        \"a knife sitting on top of a wooden table next to a knife.\",\n",
            "        \"beet tops and a chef's knife on a cutting board.\",\n",
            "        \"a pile of cabbage, noodles, and meat next to chopsticks.\",\n",
            "        \"blender half full of a slurry, next to other electrical appliances.\",\n",
            "        \"a bowl of a meal with an egg, \\\"sunny side up\\\", laid on top of everything.\",\n",
            "        \"a pork dish with onions and peppers on a white plate.\",\n",
            "        \"someone wrote a message on a bunch of bananas.\",\n",
            "        \"fruit growing on the side of a tree in a jungle.\",\n",
            "        \"a bunch of apples stacked on a plate.\",\n",
            "        \"apples on tree ready to pick in garden area.\",\n",
            "        \"a sandwich with meat, vegetables, peppers, and lettuce.\",\n",
            "        \"a pile of crab is seasoned and well cooked.\",\n",
            "        \"cut up blood red oranges lay on a blue surface.\",\n",
            "        \"a plate of oranges sliced on top of a table.\",\n",
            "        \"a pile of broccoli laying on a plastic cutting board.\",\n",
            "        \"a plate of food has noodles and broccoli.\",\n",
            "        \"a tray that has meat and carrots on a table.\",\n",
            "        \"a stuffed grey rabbit holding a pretend carrot.\",\n",
            "        \"the two hotdogs have brown mustard on them.\",\n",
            "        \"a plate with a couple of hot dogs on it.\",\n",
            "        \"view of what could possibly be a pizza with colorful vegetables as toppings.\",\n",
            "        \"a pizza that is covered in a lot of toppings.\",\n",
            "        \"a picture of a glazed donut with meat in the middle.\",\n",
            "        \"a donut is covered with glaze and sprinkles.\",\n",
            "        \"fresh red strawberries on a whipped dessert.\",\n",
            "        \"colorful icing on a pastry in the shapes of flowers.\",\n",
            "        \"the cat is sleeping comfortably on the chair.\",\n",
            "        \"a white cat curled up on a wooden chair.\",\n",
            "        \"a dog is sleeping on a pile of pillows.\",\n",
            "        \"a girl laying on the couch while on an laptop.\",\n",
            "        \"a bouguet of wilted red roses on a table.\",\n",
            "        \"a small green vase displays some small yellow blooms.\",\n",
            "        \"a tear in a black, blue, white and yellow piece of material.\",\n",
            "        \"a bed with white comforter and two black stiletto heels.\",\n",
            "        \"a plate of food consisting of rice, meat and vegetables.\",\n",
            "        \"a plate of food is centered around a portion of rice.\",\n",
            "        \"a porcelian scuplture sitting on a table next to a cup.\",\n",
            "        \"a bucket collects drips of water, inside a metal basin.\",\n",
            "        \"the back of a flat screened tv connected to a ipad.\",\n",
            "        \"a cluster of pine trees are in a barren area.\",\n",
            "        \"a bobble head is placed on a laptop keyboard.\",\n",
            "        \"a computer mouse sitting on a keyboard on a desk.\",\n",
            "        \"a silver and black wired computer mouse on a wooden surface.\",\n",
            "        \"a slug crawling on the ground around flower petals.\",\n",
            "        \"two remotes sitting on a table together.\",\n",
            "        \"the wii controller remote is turned on and has one light showing.\",\n",
            "        \"a black computer keyboard with a bunch of keys on it.\",\n",
            "        \"a keyboard that is missing some keys in the bottom row.\",\n",
            "        \"a cellphone standing upright with its camera side facing forward.\",\n",
            "        \"there is a cell phone on a table.\",\n",
            "        \"a microwave with fake eyes and a beard on it.\",\n",
            "        \"food steaming machine on the shelf of a store.\",\n",
            "        \"a yellow shallow baking dish in an open oven.\",\n",
            "        \"some food cooking on trays in an oven.\",\n",
            "        \"the toaster oven is turned on, on the counter in the kitchen.\",\n",
            "        \"a picture of a toaster plastered on a do not enter sign.\",\n",
            "        \"a old kitchen with no appliances inside of it.\",\n",
            "        \"two pictures of a hole in a counter with a lid.\",\n",
            "        \"a fridge is slightly open in a room.\",\n",
            "        \"the poster board is a special place for remembrances.\",\n",
            "        \"a stuffed animal sitting in the grass, with a book in front of it.\",\n",
            "        \"a run down windows with a broken fence outside.\",\n",
            "        \"an old and rusted clock is mounted on a brick wall.\",\n",
            "        \"a big metal clock sitting on the wall by itself.\",\n",
            "        \"bouquet of flowers sitting in a clear glass vase.\",\n",
            "        \"a blue jug in a garden filled with mud.\",\n",
            "        \"a sign that is advertising a barber shop.\",\n",
            "        \"a pair of scallop scrapbooking scissors on top of an envelope.\",\n",
            "        \"a stuffed bear is wearing a shirt with personalized writing.\",\n",
            "        \"a pair of yellow and pink teddy bears leaning against a wall.\",\n",
            "        \"a large statue of a female cow with a blonde wig.\",\n",
            "        \"rubber shoes lying on a carpet with floral prints.\",\n",
            "        \"a frog with teeth is on a purple toothbrush.\",\n",
            "        \"a worn toothbrush sits on a windowsill near the screen.\"\n",
            "    ],\n",
            "    \"query\": \"sleepy bonsai cat\",\n",
            "    \"query_template\": \"{query}\",\n",
            "    \"rad_range\": [\n",
            "        4.0,\n",
            "        4.0\n",
            "    ],\n",
            "    \"render_every\": 1000,\n",
            "    \"render_hq_video\": true,\n",
            "    \"render_lq_video\": true,\n",
            "    \"render_width\": 88,\n",
            "    \"retrieve_models\": [\n",
            "        \"clip_vit_b32\"\n",
            "    ],\n",
            "    \"retrieve_widths\": [\n",
            "        224\n",
            "    ],\n",
            "    \"seed\": 0,\n",
            "    \"sn0\": 0.0,\n",
            "    \"sn1\": 0.0,\n",
            "    \"sn_i_split\": 10000,\n",
            "    \"substeps\": 1,\n",
            "    \"test\": {\n",
            "        \"jitter\": false,\n",
            "        \"num_samples\": 256,\n",
            "        \"white_bkgd\": true\n",
            "    },\n",
            "    \"test_hq\": {\n",
            "        \"intersect_box\": false,\n",
            "        \"jitter\": false,\n",
            "        \"num_samples\": 512,\n",
            "        \"white_bkgd\": true\n",
            "    },\n",
            "    \"th_range\": [\n",
            "        0,\n",
            "        360\n",
            "    ],\n",
            "    \"transparency_loss\": \"neg_lam_transmittance_clipped\",\n",
            "    \"video_every\": 5000,\n",
            "    \"viewdirs\": false,\n",
            "    \"white_bkgd\": false,\n",
            "    \"zero_origin_lam\": 0.0\n",
            "}\n",
            "I0220 16:33:09.019079 139677965760384 run.py:112] Running executable: train\n",
            "I0220 16:33:09.100399 139677965760384 lib.py:61] Local devices: [GpuDevice(id=0, process_index=0)]\n",
            "I0220 16:33:09.100555 139677965760384 lib.py:62] All devices: [GpuDevice(id=0, process_index=0)]\n",
            "I0220 16:33:09.101736 139677965760384 model.py:136] Downloading checkpoint from https://openaipublic.azureedge.net/clip/models/5806e77cd80f8b59890b7e101eabd078d9fb84e6937f9e85e4ecb61988df416f/ViT-B-16.pt to /root/.cache/scenic/clip\n",
            "100%|███████████████████████████████████████| 335M/335M [00:06<00:00, 55.6MiB/s]\n",
            "I0220 16:33:15.546957 139677965760384 model.py:141] Converting checkpoint /root/.cache/scenic/clip/ViT-B-16.pt to numpy\n",
            "100%|█████████████████████████████████████| 1.29M/1.29M [00:00<00:00, 25.2MiB/s]\n",
            "I0220 16:33:18.606084 139677965760384 tokenizer.py:47] Downloaded vocabulary from https://github.com/openai/CLIP/blob/main/clip/bpe_simple_vocab_16e6.txt.gz?raw=true to /root/.cache/scenic/clip\n",
            "I0220 16:33:26.515315 139677965760384 model.py:136] Downloading checkpoint from https://openaipublic.azureedge.net/clip/models/40d365715913c9da98579312b702a82c18be219cc2a73407c4526f58eba950af/ViT-B-32.pt to /root/.cache/scenic/clip\n",
            "100%|████████████████████████████████████████| 338M/338M [00:03<00:00, 104MiB/s]\n",
            "I0220 16:33:30.041383 139677965760384 model.py:141] Converting checkpoint /root/.cache/scenic/clip/ViT-B-32.pt to numpy\n",
            "100%|█████████████████████████████████████| 1.29M/1.29M [00:00<00:00, 21.6MiB/s]\n",
            "I0220 16:33:31.939095 139677965760384 tokenizer.py:47] Downloaded vocabulary from https://github.com/openai/CLIP/blob/main/clip/bpe_simple_vocab_16e6.txt.gz?raw=true to /root/.cache/scenic/clip\n",
            "/usr/local/lib/python3.7/dist-packages/jax/_src/numpy/lax_numpy.py:3662: UserWarning: Explicitly requested dtype <class 'jax._src.numpy.lax_numpy.float64'> requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
            "  lax._check_user_dtype_supported(dtype, \"zeros\")\n",
            "I0220 16:33:38.730531 139677965760384 lib.py:241] n_device 1\n",
            "I0220 16:33:44.854798 139677965760384 lib.py:262] did not find checkpoint in results/'sleepy bonsai cat' 20220220-163307\n",
            "I0220 16:33:44.855000 139677965760384 helpers.py:67] starting defragment...\n",
            "I0220 16:33:44.855381 139677965760384 helpers.py:72] defragmentation not implemented\n",
            "I0220 16:33:44.866920 139677965760384 helpers.py:67] starting defragment...\n",
            "I0220 16:33:44.867252 139677965760384 helpers.py:72] defragmentation not implemented\n",
            "I0220 16:33:44.868474 139677965760384 lib.py:326] Experiment dir results\n",
            "I0220 16:33:44.868555 139677965760384 lib.py:327] Work unit dir results/'sleepy bonsai cat' 20220220-163307\n",
            "training:   0% 0/10001 [00:00<?, ?it/s]2022-02-20 16:34:41.944560: W external/org_tensorflow/tensorflow/core/common_runtime/bfc_allocator.cc:461] Allocator (GPU_0_bfc) ran out of memory trying to allocate 29.57GiB (rounded to 31750967552)requested by op \n",
            "2022-02-20 16:34:41.945298: W external/org_tensorflow/tensorflow/core/common_runtime/bfc_allocator.cc:472] ******______________________________________________________________________________________________\n",
            "2022-02-20 16:34:41.945362: E external/org_tensorflow/tensorflow/compiler/xla/pjrt/pjrt_stream_executor_client.cc:2085] Execution of replica 0 failed: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 31750967392 bytes.\n",
            "training:   0% 0/10001 [00:57<?, ?it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"run.py\", line 136, in <module>\n",
            "    run(train=lib.run_train, eval=lib.run_eval)\n",
            "  File \"run.py\", line 132, in run\n",
            "    app.run(functools.partial(main, executable_dict))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 312, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 258, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"run.py\", line 124, in main\n",
            "    **extra_args)\n",
            "  File \"/content/google-research/dreamfields/dreamfields/lib.py\", line 807, in run_train\n",
            "    yield_results=False):\n",
            "  File \"/content/google-research/dreamfields/dreamfields/lib.py\", line 426, in run_train\n",
            "    state, rays_in, keys_pstep, lrs, scs, sns, mrs, betas, accts, acclams)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/_src/traceback_util.py\", line 162, in reraise_with_filtered_traceback\n",
            "    return fun(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/_src/api.py\", line 1892, in f_pmapped\n",
            "    out_tree, out_flat = f_pmapped_(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/_src/api.py\", line 1832, in f_pmapped\n",
            "    global_arg_shapes=tuple(global_arg_shapes_flat))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/core.py\", line 1698, in bind\n",
            "    return call_bind(self, fun, *args, **params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/core.py\", line 1623, in call_bind\n",
            "    outs = primitive.process(top_trace, fun, tracers, params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/core.py\", line 1701, in process\n",
            "    return trace.process_map(self, fun, tracers, params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/core.py\", line 627, in process_call\n",
            "    return primitive.impl(f, *tracers, **params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/interpreters/pxla.py\", line 728, in xla_pmap_impl\n",
            "    return compiled_fun(*args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/interpreters/pxla.py\", line 1269, in execute_replicated\n",
            "    out_bufs = compiled.execute_sharded_on_local_devices(input_bufs)\n",
            "jax._src.traceback_util.UnfilteredStackTrace: RuntimeError: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 31750967392 bytes.\n",
            "\n",
            "The stack trace below excludes JAX-internal frames.\n",
            "The preceding is the original exception that occurred, unmodified.\n",
            "\n",
            "--------------------\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"run.py\", line 136, in <module>\n",
            "    run(train=lib.run_train, eval=lib.run_eval)\n",
            "  File \"run.py\", line 132, in run\n",
            "    app.run(functools.partial(main, executable_dict))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 312, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 258, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"run.py\", line 124, in main\n",
            "    **extra_args)\n",
            "  File \"/content/google-research/dreamfields/dreamfields/lib.py\", line 807, in run_train\n",
            "    yield_results=False):\n",
            "  File \"/content/google-research/dreamfields/dreamfields/lib.py\", line 426, in run_train\n",
            "    state, rays_in, keys_pstep, lrs, scs, sns, mrs, betas, accts, acclams)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/interpreters/pxla.py\", line 1269, in execute_replicated\n",
            "    out_bufs = compiled.execute_sharded_on_local_devices(input_bufs)\n",
            "RuntimeError: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 31750967392 bytes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Ff6hcwQZtqva"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgSvskIfJn9I"
      },
      "source": [
        "# Install dependencies.\n",
        "After running, you may need to restart your runtime (Runtime > Restart Runtime)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Download and install scenic, which wraps CLIP\n",
        "!git clone https://github.com/google-research/scenic.git\n",
        "%cd /content/scenic\n",
        "!git checkout 2eaa89e4c166576ca95e09de48cd068821ed7e9e\n",
        "%cd -\n",
        "\n",
        "# Overwrite dependencies that pull in tf-nightly to speed up install\n",
        "with open('/content/scenic/setup.py', 'r') as f:\n",
        "  lines = f.readlines()\n",
        "with open('/content/scenic/setup.py', 'w') as f:\n",
        "  for line in lines:\n",
        "    if not re.search(r'\\W+\"[a-z\\-]+-nightly\",\\n', line):\n",
        "      f.write(line)\n",
        "\n",
        "!cd /content/scenic && pip install ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "t_27ooF5Xxzn",
        "outputId": "cb4b63ec-ed5e-4a5b-8a5d-5a508bbfa9ca"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'scenic'...\n",
            "remote: Enumerating objects: 1941, done.\u001b[K\n",
            "remote: Counting objects: 100% (219/219), done.\u001b[K\n",
            "remote: Compressing objects: 100% (122/122), done.\u001b[K\n",
            "remote: Total 1941 (delta 134), reused 120 (delta 97), pack-reused 1722\u001b[K\n",
            "Receiving objects: 100% (1941/1941), 11.02 MiB | 26.50 MiB/s, done.\n",
            "Resolving deltas: 100% (1218/1218), done.\n",
            "[Errno 2] No such file or directory: '/content/scenic'\n",
            "/content/google-research/dreamfields\n",
            "fatal: reference is not a tree: 2eaa89e4c166576ca95e09de48cd068821ed7e9e\n",
            "/content\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-04813efb5693>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Overwrite dependencies that pull in tf-nightly to speed up install\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/scenic/setup.py'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m   \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/scenic/setup.py'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/scenic/setup.py'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VXC9um2lIejR"
      },
      "outputs": [],
      "source": [
        "# Download Dream Fields code\n",
        "!apt install subversion\n",
        "!svn export https://github.com/google-research/google-research/trunk/dreamfields\n",
        "\n",
        "# Install Dream Fields\n",
        "with open('/content/dreamfields/setup.py', 'w') as f:\n",
        "  f.write(\"\"\"\n",
        "from setuptools import setup, find_packages\n",
        "\n",
        "setup(\n",
        "    name=\"dreamfields\",\n",
        "    version=\"0.1.0\",\n",
        "    packages=find_packages(include=[\"dreamfields\", \"dreamfields.*\"]),\n",
        "    description=\"Text to 3D\",\n",
        "    author=\"Google Research\",\n",
        "    install_requires=[\n",
        "      \"absl-py\",\n",
        "      \"clu==0.0.4\",\n",
        "      \"clip @ git+https://github.com/openai/CLIP.git\",\n",
        "      \"dm_pix\",\n",
        "      \"jax\",\n",
        "      \"jaxlib\",\n",
        "      \"flax\",\n",
        "      \"matplotlib>=3.3.0\",\n",
        "      \"mediapy\",\n",
        "      \"ml_collections\",\n",
        "      \"numpy\",\n",
        "      \"regex\",\n",
        "      \"scipy\",\n",
        "      \"tensorflow==2.7.0\",\n",
        "      \"KERAS==2.7.0\",\n",
        "      \"tqdm\",\n",
        "      \"torch\"\n",
        "    ],\n",
        ")\n",
        "\"\"\")\n",
        "!pip install --upgrade pip\n",
        "!cd /content/dreamfields && pip install ."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Uninstall and reinstall packages to deal with version mismatch\n",
        "!pip uninstall --yes numpy matplotlib\n",
        "!pip install --upgrade numpy matplotlib"
      ],
      "metadata": {
        "id": "0GgxgrMLeeH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEj5tFx4Jmbh"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prevent tensorflow from hogging memory\n",
        "import tensorflow as tf\n",
        "tf.config.experimental.set_visible_devices([], \"GPU\")"
      ],
      "metadata": {
        "id": "9ataxIm_pF2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6uQJRMw-NLKQ"
      },
      "outputs": [],
      "source": [
        "%env XLA_PYTHON_CLIENT_PREALLOCATE=false\n",
        "\n",
        "import jax\n",
        "try:\n",
        "  import jax.tools.colab_tpu\n",
        "  jax.tools.colab_tpu.setup_tpu()\n",
        "  default_precision = 'bfloat16'\n",
        "  use_gpu = False\n",
        "except KeyError as e:\n",
        "  print('No TPUs available')\n",
        "  default_precision = 'tensorfloat32'\n",
        "  use_gpu = True\n",
        "\n",
        "print(jax.devices())\n",
        "\n",
        "if use_gpu:\n",
        "  !nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.6.0 keras==2.6.0"
      ],
      "metadata": {
        "id": "782jHsSlBEAq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8VekUreA5mmu"
      },
      "outputs": [],
      "source": [
        "import collections\n",
        "from collections import defaultdict\n",
        "import functools\n",
        "import os\n",
        "import random as py_random\n",
        "import time\n",
        "from typing import Optional, Sequence\n",
        "\n",
        "from absl import logging\n",
        "from clu import metric_writers\n",
        "import flax \n",
        "import flax.linen as nn\n",
        "from flax.training import checkpoints\n",
        "from IPython.display import clear_output, display, Image\n",
        "import jax\n",
        "import jax.numpy as np\n",
        "from jax import random\n",
        "import matplotlib.pyplot as plt\n",
        "import mediapy as media\n",
        "import ml_collections\n",
        "import numpy as onp\n",
        "from scipy import stats\n",
        "import tensorflow.io.gfile as gfile\n",
        "import tqdm\n",
        "\n",
        "nn.enable_named_call()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cyOz2vnWj7WI"
      },
      "outputs": [],
      "source": [
        "from dreamfields import augment\n",
        "from dreamfields import helpers\n",
        "from dreamfields import log\n",
        "from dreamfields import mipnerf\n",
        "from dreamfields import scene\n",
        "from dreamfields import schedule\n",
        "from dreamfields.config.config_mq import get_config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrpIOPoUGCXS"
      },
      "source": [
        "# Configure run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oaZ0HdBJr8CI",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Training hyperparameters\n",
        "#@markdown More parameters are documented [on GitHub](https://github.com/google-research/google-research/blob/master/dreamfields/dreamfields/config/config_base.py).\n",
        "\n",
        "#@markdown **Natural language query and seed.**\n",
        "query = 'a high-quality 3d render of a jenga tower'  #@param {type:'string'}\n",
        "seed = 0  #@param {type:'integer'}\n",
        "\n",
        "#@markdown **CLIP guidance model.** `clip_vit_b16` is suggested.\n",
        "loss_model = \"clip_vit_b16\" #@param [\"clip_vit_b32\", \"clip_vit_b16\", \"clip_resnet_50\", \"clip_resnet_101\", \"clip_resnet_50x4\"]\n",
        "\n",
        "\n",
        "#@markdown **Quality settings.** Increase `iters`, `render_width`, `num_samples` or `n_local_aug` for higher quality results, or lower to run faster and reduce memory usage.\n",
        "iters = 2000  #@param {type:'integer'}\n",
        "config = get_config(iters=iters)\n",
        "config.render_width = 88  #@param {type:'integer'}\n",
        "config.crop_width = 80  #@param {type:'integer'}\n",
        "config.num_samples =   64#@param {type:'integer'}\n",
        "config.n_local_aug = 4 #@param {type:\"slider\", min:1, max:32, step:1}\n",
        "assert config.crop_width <= config.render_width\n",
        "\n",
        "config.query = query\n",
        "config.seed = seed\n",
        "config.loss_model = loss_model\n",
        "\n",
        "#@markdown **Save memory by recomputation**. These options reduce memory usage but slow down optimization.\n",
        "config.remat_image_encoder = False #@param {type:\"boolean\"}\n",
        "config.remat_mlp = True #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown **Camera sampling.** These define 3D data augs for viewing the scene.\n",
        "min_zoom = 1.2 #@param {type:\"slider\", min:1, max:2, step:0.1}\n",
        "max_zoom = 1.2 #@param {type:\"slider\", min:1, max:2, step:0.1}\n",
        "min_elevation = 30 #@param {type:\"slider\", min:0, max:90, step:1}\n",
        "max_elevation = 30 #@param {type:\"slider\", min:0, max:90, step:1}\n",
        "min_azimuth = 0 #@param {type:\"slider\", min:0, max:90, step:1}\n",
        "max_azimuth = 360 #@param {type:\"slider\", min:0, max:360, step:1}\n",
        "\n",
        "config.focal_mult_range = [min_zoom, max_zoom]  # Zoom augmentations.\n",
        "config.th_range = [0, 360]  # Optimize in 360 degrees around object.\n",
        "config.phi_range = [-max_elevation, -min_elevation]  # Camera elevation, neg degrees above equator.\n",
        "config.ema_scene_origin = True  # Set to False if object clipped too much.\n",
        "# Freeze tracked origin initially\n",
        "config.fix_origin_iters = 200  #@param {type:\"integer\"}\n",
        "config.origin_decay = 0.9995  #@param {type:\"number\"}\n",
        "\n",
        "#@markdown **Learning rate schedule**. Linear warmup from lr0 to lr1 then linear decay to lr2. Try a higher lr1 if impatient.\n",
        "lr_warmup_iters = 100  #@param {type:'number'}\n",
        "config.lr_i_split = lr_warmup_iters\n",
        "config.lr0 = 1e-5  #@param {type:'number'}\n",
        "config.lr1 = 5e-4  #@param {type:'number'}\n",
        "config.lr2 = 1e-4  #@param {type:'number'}\n",
        "\n",
        "# Reduce size of scene to get away with fewer samples per ray\n",
        "config.mr0 = 1.\n",
        "config.mr1 = 1.\n",
        "# Duration to anneal in transmittance loss.\n",
        "# Increase if transmittance goes to 1 (empty scene).\n",
        "config.acc_target_i_split = 100  #@param {type:\"integer\"}\n",
        "config.acc_target0 = 0.5\n",
        "config.acc_target0 = 0.1\n",
        "# Weight on transmittance loss\n",
        "config.acc_lam = 0.25\n",
        "\n",
        "#@markdown **MLP architecture.** Shallower and narrower than in the paper.\n",
        "residual_blocks = 2 #@param {type:\"slider\", min:1, max:6, step:1}\n",
        "min_mlp_width = 128  #@param {type:'number'}\n",
        "max_mlp_width = 192  #@param {type:'number'}\n",
        "config.mipnerf.features_early = [min_mlp_width]\n",
        "config.mipnerf.features_residual = [(max_mlp_width, min_mlp_width)] * residual_blocks\n",
        "config.mipnerf.features_late = [4]\n",
        "\n",
        "#@markdown **Coarse to fine**: Integrate positional encoding over larger regions at the start of training. log scale 1 is used in Dream Fields (i.e. no coarse to fine, as in mip-NeRF).\n",
        "initial_log_posenc_scale = 1 #@param {type:\"slider\", min:1, max:8, step:0.1}\n",
        "coarse_to_fine_iters = 1000 #@param {type:\"number\"}\n",
        "config.decay_start = initial_log_posenc_scale\n",
        "config.decay_iters = coarse_to_fine_iters\n",
        "\n",
        "#@markdown **Logging parameters.** Increase the final render quality here.\n",
        "\n",
        "# Save model checkpoints\n",
        "config.checkpoint_every = iters\n",
        "# Enable low-quality video.\n",
        "config.render_lq_video = True\n",
        "config.video_every = iters\n",
        "config.lq_video_n_frames = 48  #@param {type:'integer'}\n",
        "config.lq_video_width = 200  #@param {type:'integer'}\n",
        "config.test.num_samples = 128  # Increase if desired to reduce aliasing.\n",
        "# Disable HQ video.\n",
        "config.render_hq_video = False\n",
        "config.hq_video_every = 100000\n",
        "# Disable validation view rendering.\n",
        "config.render_every = 100000\n",
        "\n",
        "timestr = time.strftime('%Y%m%d-%H%M%S')\n",
        "experiment_dir = f'/content/results/{timestr} {config.query}'\n",
        "work_unit_dir = f'{experiment_dir}/1'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLjBuwrkGFkQ"
      },
      "source": [
        "# Set seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KB4YHW5UF-0e"
      },
      "outputs": [],
      "source": [
        "py_random.seed(config.seed * jax.process_count() + jax.process_index())\n",
        "onp.random.seed(config.seed * jax.process_count() + jax.process_index())\n",
        "rng = helpers.RngGen(\n",
        "    jax.random.fold_in(jax.random.PRNGKey(config.seed), jax.process_index()))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training code"
      ],
      "metadata": {
        "id": "f3Gy03snwOmU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MipMLPLate(nn.Module):\n",
        "  \"\"\"MLP architecture.\"\"\"\n",
        "  activation: str\n",
        "  features_early: Sequence[int]\n",
        "  features_residual: Sequence[Sequence[int]]\n",
        "  features_late: Sequence[int]\n",
        "  fourfeat: bool\n",
        "  max_deg: int\n",
        "  use_cov: bool\n",
        "  dropout_rate: float\n",
        "  remat: bool\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, mean, cov=None, x_late=None, decayscale=1.,\n",
        "               *, deterministic):\n",
        "    \"\"\"Run MLP.\"\"\"\n",
        "    # Integrate the positional encoding over a region centered at mean.\n",
        "    if not self.fourfeat:\n",
        "      # Axis-aligned positional encoding.\n",
        "      feat = 2**np.arange(self.max_deg)[:, None, None] * np.eye(3)\n",
        "      feat = feat.reshape(-1, 3)\n",
        "    else:\n",
        "      # Random Fourier Feature positional encoding. Fix the PRNGKey used for the\n",
        "      # fourier feature basis so the encoding does not change over iterations.\n",
        "      fourfeat_key = random.PRNGKey(124124)\n",
        "      dirs = random.normal(fourfeat_key, (3, 128))\n",
        "      dirs = dirs / np.linalg.norm(dirs, axis=-1, keepdims=True)\n",
        "      rads = 2 ** (self.max_deg * random.uniform(fourfeat_key, (128,)))\n",
        "      feats = (rads * dirs).astype(np.int32)\n",
        "      feats = np.concatenate([np.eye(3), feats], 1).astype(np.float32)\n",
        "      feat = feats.T\n",
        "\n",
        "    mean_proj = (mean[Ellipsis, None] * feat.T).sum(-2)\n",
        "    if self.use_cov:\n",
        "      cov_diag_proj = ((cov[Ellipsis, None] * feat.T).sum(-2) * feat.T).sum(-2)\n",
        "      decay = np.exp(-.5 * cov_diag_proj * decayscale**2)\n",
        "    else:\n",
        "      # Disable IPE\n",
        "      decay = 1.\n",
        "    x = np.concatenate([decay * np.cos(mean_proj),\n",
        "                        decay * np.sin(mean_proj)], -1)\n",
        "\n",
        "    # Network\n",
        "    activation = nn.__getattribute__(self.activation)\n",
        "    if self.remat:\n",
        "      activation = jax.remat(activation)\n",
        "    for feat in self.features_early:\n",
        "      x = activation(nn.Dense(feat)(x))\n",
        "      x = nn.Dropout(self.dropout_rate)(\n",
        "          x, deterministic=deterministic)\n",
        "\n",
        "    for feat_block in self.features_residual:\n",
        "      norm = nn.LayerNorm()\n",
        "      if self.remat:\n",
        "        norm = jax.remat(norm)\n",
        "      h = norm(x)\n",
        "      for l, feat in enumerate(feat_block):\n",
        "        h = nn.Dense(feat)(h)\n",
        "        h = nn.Dropout(self.dropout_rate)(\n",
        "            h, deterministic=deterministic)\n",
        "        if l < len(feat_block) - 1:  # don't activate right before the residual\n",
        "          h = activation(h)\n",
        "      x = x + h\n",
        "\n",
        "    if x_late is not None:\n",
        "      x = np.concatenate([x, x_late], axis=-1)\n",
        "    for feat in self.features_late[:-1]:\n",
        "      x = activation(nn.Dense(feat)(x))\n",
        "      x = nn.Dropout(self.dropout_rate)(\n",
        "          x, deterministic=deterministic)\n",
        "    x = nn.Dense(self.features_late[-1])(x)  # don't activate output\n",
        "    return x\n",
        "\n",
        "\n",
        "def init_nerf_model(key, config):\n",
        "  \"\"\"Initialize NeRF MLP.\"\"\"\n",
        "  if config.parameterization == 'mipnerf':\n",
        "    model = MipMLPLate(\n",
        "        activation=config.mlp_activation,\n",
        "        features_early=config.features_early,\n",
        "        features_residual=config.features_residual,\n",
        "        features_late=config.features_late,\n",
        "        max_deg=config.posenc_deg,\n",
        "        fourfeat=config.fourfeat,\n",
        "        use_cov=config.mipnerf.get('use_cov', True),\n",
        "        dropout_rate=config.mipnerf.get('dropout_rate', 0.),\n",
        "        remat=config.get('remat_mlp', False))\n",
        "    if config.viewdirs:\n",
        "      x_late = scene.posenc(np.zeros([1, 3]), config.posenc_dirs_deg)\n",
        "    else:\n",
        "      x_late = None\n",
        "    variables = model.init(\n",
        "        key, np.zeros([1, 3]), np.zeros([1, 3, 3]), x_late, deterministic=True)\n",
        "\n",
        "    render_rays = functools.partial(mipnerf.render_rays_mip, model=model)\n",
        "  else:\n",
        "    raise ValueError\n",
        "\n",
        "  return variables, render_rays\n",
        "\n",
        "\n",
        "class DreamField:\n",
        "  \"\"\"Trainable Dream Field model.\"\"\"\n",
        "\n",
        "  def __init__(self, config):\n",
        "    self.config = config\n",
        "\n",
        "  def run_train(self,\n",
        "                experiment_dir,\n",
        "                work_unit_dir,\n",
        "                rng: helpers.RngGen,\n",
        "                yield_results=False):\n",
        "    \"\"\"Train a Dream Field and save results to work_unit_dir.\"\"\"\n",
        "    t_start = time.time()\n",
        "    config = self.config\n",
        "\n",
        "    logging.info('Local devices: %s', jax.local_devices())\n",
        "    logging.info('All devices: %s', jax.devices())\n",
        "\n",
        "    ## Load CLIP\n",
        "    encode_image, encode_text, preprocess_image, tokenize_fn = (\n",
        "        helpers.load_image_text_model(config.loss_model))\n",
        "\n",
        "    ## Pick a prompt\n",
        "    template = config.get('query_template', '{query}')\n",
        "    query = template.format(query=config.query)\n",
        "    z_clip = encode_text(tokenize_fn(query))\n",
        "    del encode_text, tokenize_fn  # Clean up text encoder.\n",
        "\n",
        "    ## Scene origin manually tracked\n",
        "    scene_origin = scene.EMA(\n",
        "        np.zeros(3, dtype=np.float64), decay=config.get('origin_decay', 0.999))\n",
        "\n",
        "    def train_step(state, rays, key, *multistep_constants):\n",
        "      \"\"\"Perform a training iteration, optionally composed of multiple substeps.\n",
        "\n",
        "      Using multiple substeps slightly reduces training time, but only one\n",
        "      substep per training iteration is used in experiments.\n",
        "\n",
        "      Args:\n",
        "        state: Optimizer state.\n",
        "        rays: Camera rays for rendering, shared across all substeps.\n",
        "        key: PRNGKey for random number generation (e.g. for augmentations).\n",
        "        *multistep_constants: Training constants that can vary across substeps.\n",
        "          6 arrays of constants of length config.substeps are expected:\n",
        "            (1) lrs: learning rates\n",
        "            (2) scs: scale factor for integrated positional encoding. Larger\n",
        "                scales lead to a blurrier appearance. A constant sc=1 is the\n",
        "                standard mip-NeRF IPE, and used by Dream Fields.\n",
        "            (3) sns: standard deviation of pre-activation noise for NeRF\n",
        "                density. Dream Fields use sn=0.\n",
        "                  density(x) = softplus(s(x) + eps), eps ~ N(0, sn^2)\n",
        "            (4) mrs: norm of radiance mask, defining scene bounds.\n",
        "            (5) acct: transmittance loss hyperparameter, defining the target\n",
        "                average opacity. This is 1 - tau (target transmittance).\n",
        "            (6) acclam: weight of transmittance loss.\n",
        "\n",
        "      Returns:\n",
        "        state: Updated optimizer state.\n",
        "        last_augs: Augmented views of renderings from the last substep.\n",
        "        mean_losses: Dictionary of losses averaged over replicas and substeps.\n",
        "        scene_origin: Updated origin of the scene, based on the center of mass.\n",
        "      \"\"\"\n",
        "      # NOTE(jainajay): rays are shared across all substeps\n",
        "      pmean = functools.partial(jax.lax.pmean, axis_name='batch')\n",
        "      psum = functools.partial(jax.lax.psum, axis_name='batch')\n",
        "\n",
        "      def loss_fn(params, key, sc, sn, mr, acct, acclam):\n",
        "        render_key, aug_key, key = random.split(key, 3)\n",
        "\n",
        "        # Render from nerf\n",
        "        (rgb_est_flat, _, acc_est_flat), aux = render_rays(\n",
        "            rays=rays,\n",
        "            variables=params,\n",
        "            rng=render_key,\n",
        "            config=config,\n",
        "            sc=sc,\n",
        "            sigma_noise_std=sn,\n",
        "            mask_rad=mr,\n",
        "            origin=scene_origin.value,\n",
        "            train=True)\n",
        "        rgb_est = scene.gather_and_reshape(rgb_est_flat, config.render_width, 3)\n",
        "        acc_est = scene.gather_and_reshape(acc_est_flat, config.render_width, 1)\n",
        "        # Make augmentations process specific\n",
        "        aug_key = random.fold_in(aug_key, pid)\n",
        "        # Perform augmentations and resize to clip_width\n",
        "        augs = augment.augment_rendering(config, rgb_est, acc_est, aug_key)\n",
        "\n",
        "        # Run through CLIP\n",
        "        augs_pre = preprocess_image(augs)\n",
        "        with jax.default_matmul_precision(default_precision):\n",
        "          if config.get('remat_image_encoder', False):\n",
        "            z_est = jax.remat(encode_image)(augs_pre)\n",
        "          else:\n",
        "            z_est = encode_image(augs_pre)\n",
        "        clip_loss = -(z_est * z_clip).sum(-1).mean()\n",
        "        total_loss = clip_loss\n",
        "\n",
        "        transparency_loss = config.get('transparency_loss', None)\n",
        "        acc_mean = np.mean(acc_est)\n",
        "        aux['losses']['acc_mean'] = acc_mean\n",
        "        if transparency_loss == 'neg_lam_transmittance_clipped':\n",
        "          # Compute the Dream Fields transmittance loss for scene sparsity.\n",
        "          trans_mean = 1 - acc_mean\n",
        "          trans_mean_clipped = np.minimum(1 - acct, trans_mean)\n",
        "          reg = acclam * trans_mean_clipped\n",
        "          total_loss -= reg\n",
        "\n",
        "          aux['losses']['trans_mean_clipped'] = trans_mean_clipped\n",
        "          aux['losses']['acc_reg_additive'] = reg\n",
        "        else:\n",
        "          assert transparency_loss is None\n",
        "\n",
        "        # Compute a weighted mean of each replica's estimated scene origin,\n",
        "        # since replicas get a different subset of rays\n",
        "        total_sigma = psum(aux['scene_origin_sigma'])\n",
        "        aux['scene_origin'] = psum(aux['scene_origin'] *\n",
        "                                   aux['scene_origin_sigma'] / total_sigma)\n",
        "\n",
        "        aux['losses'].update({\n",
        "            'clip_loss': clip_loss,\n",
        "            'loss': total_loss,\n",
        "        })\n",
        "        aux['augs'] = augs\n",
        "        return total_loss, aux\n",
        "\n",
        "      grad_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
        "\n",
        "      # Scan over substeps\n",
        "      def body_fn(state, step_constants):\n",
        "        lr, step_constants = step_constants[0], step_constants[1:]\n",
        "        grad_fn_key, _ = random.split(key, 2)\n",
        "        (_, aux), grad = grad_fn(state.target, grad_fn_key, *step_constants)\n",
        "        grad = pmean(grad)  # all-reduce grad\n",
        "        aux['losses'] = pmean(aux['losses'])\n",
        "        aux['losses']['grad_norm'] = helpers.tree_norm(grad)\n",
        "        state = state.apply_gradient(grad, learning_rate=lr)\n",
        "        return state, aux\n",
        "\n",
        "      assert len(multistep_constants) == 6\n",
        "      multistep_constants = np.array(multistep_constants).T\n",
        "\n",
        "      if config.substeps == 1:\n",
        "        state, aux = body_fn(state, np.squeeze(multistep_constants))\n",
        "        last_augs = aux['augs']\n",
        "      else:\n",
        "        state, aux = jax.lax.scan(body_fn, state, multistep_constants)\n",
        "        # Augmentations from last substep.\n",
        "        # Shape: [n_local_aug, clip_width, clip_width, 3]\n",
        "        last_augs = aux['augs'][-1]\n",
        "\n",
        "      # Average each type of loss over substeps\n",
        "      mean_losses = jax.tree_map(np.mean, aux['losses'])\n",
        "      return state, last_augs, mean_losses, aux['scene_origin']\n",
        "\n",
        "    train_pstep = jax.pmap(\n",
        "        train_step,\n",
        "        axis_name='batch',\n",
        "        in_axes=(0, 0, 0, None, None, None, None, None, None))\n",
        "\n",
        "    onp.random.seed(config.seed)\n",
        "\n",
        "    n_device = jax.local_device_count()\n",
        "    pid = jax.process_index()\n",
        "    logging.info('n_device %d', n_device)\n",
        "    ## Modified NeRF architecture, with swish, softplus, skips.\n",
        "    variables, render_rays = init_nerf_model(rng.advance(1), config)\n",
        "    state = flax.optim.Adam(config.lr0, eps=config.adam_eps).create(variables)\n",
        "\n",
        "    ## Try to restore a checkpoint.\n",
        "    restore_dir = config.get('restore_dir', experiment_dir)\n",
        "    restore_dir = os.path.join(restore_dir, os.path.basename(work_unit_dir))\n",
        "    if checkpoints.latest_checkpoint(restore_dir):\n",
        "      restored = checkpoints.restore_checkpoint(\n",
        "          restore_dir,\n",
        "          target={\n",
        "              'origin': np.zeros(3),\n",
        "              'state': state,\n",
        "              'vars': variables\n",
        "          })\n",
        "      scene_origin.value = onp.array(restored['origin'])\n",
        "      state = restored['state']\n",
        "      variables = restored['vars']\n",
        "      logging.info('restored checkpoint from step %d', state.state.step)\n",
        "    else:\n",
        "      logging.info('did not find checkpoint in %s', restore_dir)\n",
        "\n",
        "    ## Replicate state.\n",
        "    step_init = state.state.step\n",
        "    helpers.defragment()\n",
        "    state = flax.jax_utils.replicate(state, jax.devices())\n",
        "    helpers.defragment()\n",
        "\n",
        "    ## pmap'd rendering for test time evaluation.\n",
        "    kwargs_test = dict(rng=None, sigma_noise_std=0.)\n",
        "    config_test = ml_collections.ConfigDict(config)\n",
        "    config_test.update(config.test)\n",
        "\n",
        "    @functools.partial(jax.pmap, in_axes=(0, None, None, None))\n",
        "    def render_test_p(rays, variables, sc=1., mr=1.):\n",
        "      return render_rays(\n",
        "          rays=rays,\n",
        "          variables=variables,\n",
        "          sc=sc,\n",
        "          mask_rad=mr,\n",
        "          origin=scene_origin.value,\n",
        "          config=config_test,\n",
        "          **kwargs_test)[0]\n",
        "\n",
        "    def render_test(rays, variables, sc=1., mr=1.):\n",
        "      sh = rays[0].shape\n",
        "      rays = [x.reshape((jax.device_count(), -1) + x.shape[1:]) for x in rays]\n",
        "      out = render_test_p(rays, variables, sc, mr)\n",
        "      out = [x.reshape(sh[:-1] + (-1,)) for x in out]\n",
        "      return out\n",
        "\n",
        "    def render_loop(rays, variables, sc=1., mr=1., chunk=2**13):\n",
        "      sh = list(rays[0].shape[:-1])\n",
        "      rays = [x.reshape((-1,) + x.shape[-1:]) for x in rays]\n",
        "      outs = [\n",
        "          render_test([x[i:i + chunk]\n",
        "                       for x in rays], variables, sc, mr)\n",
        "          for i in range(0, rays[0].shape[0], chunk)\n",
        "      ]\n",
        "      outs = [\n",
        "          np.reshape(np.concatenate([z[i]\n",
        "                                     for z in outs]), sh + [-1])\n",
        "          for i in range(3)\n",
        "      ]\n",
        "      return outs\n",
        "\n",
        "    ## Training loop\n",
        "    t_total = 0.\n",
        "    logging.info('Experiment dir %s', experiment_dir)\n",
        "    logging.info('Work unit dir %s', work_unit_dir)\n",
        "    gfile.makedirs(work_unit_dir)\n",
        "\n",
        "    if jax.process_index() == 0:\n",
        "      train_config = config.copy_and_resolve_references()\n",
        "      log.write_config_json(train_config, work_unit_dir)\n",
        "\n",
        "    # Scale instrinsics to different resolutions.\n",
        "    hwf_clip_r = scene.scale_intrinsics(config.retrieve_widths[0])\n",
        "    hwf_base = scene.scale_intrinsics(config.render_width)\n",
        "    hwf_video = scene.scale_intrinsics(config.get('lq_video_width', 300.))\n",
        "    hwf_video_hq = scene.scale_intrinsics(config.get('hq_video_width', 400.))\n",
        "\n",
        "    # JIT compile ray generation\n",
        "    @jax.jit\n",
        "    def camera_ray_batch_base(p, focal_mult):\n",
        "      return scene.camera_ray_batch(p, *hwf_base[:2], hwf_base[2] * focal_mult)\n",
        "\n",
        "    @jax.jit\n",
        "    def sample_pose_focal(key):\n",
        "      return scene.sample_camera(key, config.th_range, config.phi_range,\n",
        "                                 config.rad_range, config.focal_mult_range)\n",
        "\n",
        "    shard_rays_jit = jax.jit(functools.partial(scene.shard_rays))\n",
        "\n",
        "    def sample_iter_data(key, step):\n",
        "      # Sample pose, focal length multiplier.\n",
        "      pose, rad, focal_mult = sample_pose_focal(key)\n",
        "\n",
        "      # Generate rays, shaped for pmap over devices.\n",
        "      rays = camera_ray_batch_base(pose, focal_mult)\n",
        "      rays_in = shard_rays_jit(rays)\n",
        "      # Select rays for this process\n",
        "      rays_in = jax.tree_map(lambda x: x[pid], rays_in)\n",
        "\n",
        "      substeps = np.arange(start=step, stop=step + config.substeps, step=1)\n",
        "\n",
        "      # mip-NeRF scale annealing.\n",
        "      decays = config.mipnerf.decay_start * (\n",
        "          1 - substeps / config.mipnerf.decay_iters)\n",
        "      scs = np.maximum(1., 2**decays)\n",
        "\n",
        "      # Sigma noise annealing.\n",
        "      sns = schedule.sigma_noise_std_fn(\n",
        "          substeps, i_split=config.sn_i_split, sn0=config.sn0, sn1=config.sn1)\n",
        "\n",
        "      # Scene bounds annealing.\n",
        "      mrs = schedule.mask_rad_fn(\n",
        "          substeps, i_split=config.mr_i_split, mr0=config.mr0, mr1=config.mr1)\n",
        "\n",
        "      # Anneal target opacity (1 - transmittance).\n",
        "      accts = schedule.anneal_exponentially(substeps, config.acc_target_i_split,\n",
        "                                            config.acc_target0,\n",
        "                                            config.acc_target1)\n",
        "      # The area of an object on the image plane grows with the focal length\n",
        "      # and shrinks with increasing camera radius. Scale target opacity\n",
        "      # proportionally with the squared focal multiplier and inversely\n",
        "      # proportionally with the squared camera radius. For consistency with\n",
        "      # early experiments that did not use this scaling, we also scale by a\n",
        "      # constant, 1 / (4^2 * 1.2).\n",
        "      acct_scaling = focal_mult**2 / ((rad / 4.)**2) / 1.2\n",
        "      accts = np.minimum(1., acct_scaling * accts)\n",
        "      acclams = np.where(substeps < config.acc_lam_after, 0., config.acc_lam)\n",
        "\n",
        "      # Learning rate schedule.\n",
        "      # NOTE: vectorized calculation of lrs doesn't work with multiple substeps\n",
        "      lrs = schedule.lr_fn(\n",
        "          substeps,\n",
        "          i_split=config.lr_i_split,\n",
        "          i_end=config.iters,\n",
        "          lr0=config.lr0,\n",
        "          lr1=config.lr1,\n",
        "          lr2=config.lr2,\n",
        "          cosine_decay=config.lr_cosine_decay)\n",
        "\n",
        "      return substeps, rays_in, lrs, scs, sns, mrs, accts, acclams\n",
        "\n",
        "    pbar = tqdm.trange(\n",
        "        step_init,\n",
        "        config.iters + config.substeps,\n",
        "        config.substeps,\n",
        "        desc='training')\n",
        "    for i in pbar:\n",
        "      substeps, rays_in, lrs, scs, sns, mrs, accts, acclams = (\n",
        "          sample_iter_data(rng.advance(1), i))\n",
        "      l = substeps[-1]\n",
        "\n",
        "      keys_pstep = rng.split(n_device)\n",
        "      # NOTE: loss is averaged across substeps.\n",
        "      new_state, augs, mean_losses, new_scene_origin = train_pstep(\n",
        "          state, rays_in, keys_pstep, lrs, scs, sns, mrs, accts, acclams)\n",
        "\n",
        "      # Reduce across devices\n",
        "      mean_losses = jax.tree_map(np.mean, mean_losses)\n",
        "\n",
        "      # Gradient skipping if nan.\n",
        "      if (helpers.all_finite_tree(mean_losses) and\n",
        "          helpers.all_finite_tree(new_state)):\n",
        "        state = new_state\n",
        "      else:\n",
        "        logging.warn('Skipping update on step %d. non-finite loss or state', i)\n",
        "        continue\n",
        "\n",
        "      # Update scene origin.\n",
        "      if (config.get('ema_scene_origin', False) and\n",
        "          l > config.get('fix_origin_iters', -1)):\n",
        "        if helpers.all_finite(new_scene_origin):\n",
        "          scene_origin.update(new_scene_origin[0])\n",
        "        else:\n",
        "          logging.warn(\n",
        "              'Skipping origin update on step %d. '\n",
        "              'non-finite origin. old: %s skipped update: %s', i,\n",
        "              scene_origin.value, new_scene_origin)\n",
        "\n",
        "      ## Yield results, for display in colab.\n",
        "      augs = augs.reshape(-1, *augs.shape[2:])  # devices, n_localaug, HWC->BHWC\n",
        "      if yield_results:\n",
        "        yield mean_losses, augs, scene_origin.value, lrs[-1]\n",
        "      else:\n",
        "        yield None\n",
        "      pbar.set_description(f'CLIP loss: {mean_losses[\"clip_loss\"]:.4f}')\n",
        "\n",
        "      ## Logging.\n",
        "      if i == 0:\n",
        "        continue\n",
        "\n",
        "      if i % config.render_every == 0:\n",
        "        variables = helpers.state_to_variables(state)\n",
        "        cam2world = scene.pose_spherical(30., -45., 4.)\n",
        "        rays = scene.camera_ray_batch(cam2world, *hwf_clip_r)\n",
        "\n",
        "        # Render with no scale manipulation.\n",
        "        outs = render_loop(rays, variables, sc=1., mr=mrs[-1], hq=True)\n",
        "        outs = [np.squeeze(x) for x in outs]\n",
        "        step_images = {\n",
        "            'render/rgb': outs[0][None],\n",
        "            'render/depth': outs[1][None, ..., None],\n",
        "            'render/acc': outs[2][None, ..., None],\n",
        "            'render/augmentations': log.make_image_grid(augs[:8])\n",
        "        }\n",
        "\n",
        "        fig = plt.figure()\n",
        "        plt.imshow(1. / np.maximum(config.near, outs[1]))\n",
        "        plt.colorbar()\n",
        "        plt.title('disparity')\n",
        "        disparity = log.plot_to_image(fig)\n",
        "        step_images['render/disparity'] = disparity\n",
        "\n",
        "      if config.render_lq_video and (i == config.iters or\n",
        "          config.video_every and i % config.video_every == 0):\n",
        "        def rays_theta(th):\n",
        "          cam2world = scene.pose_spherical(th, -30., 4.)\n",
        "          return scene.camera_ray_batch(cam2world, *hwf_video)\n",
        "\n",
        "        th_range = np.linspace(\n",
        "            0, 360, config.get('lq_video_n_frames', 60), endpoint=False)\n",
        "        variables = helpers.state_to_variables(state)\n",
        "        frames_all = [\n",
        "            render_loop(rays_theta(th), variables, scs[-1], mrs[-1])\n",
        "            for th in tqdm.tqdm(th_range, desc='render video')\n",
        "        ]\n",
        "\n",
        "        videos = [[np.squeeze(f[i]) for f in frames_all] for i in range(3)]\n",
        "        for video, label in zip(videos, 'rgb depth acc'.split()):\n",
        "          scale = (label == 'depth')\n",
        "          log.log_video(\n",
        "              None, video, 'frames', label, l, work_unit_dir, scale=scale)\n",
        "\n",
        "      defrag_every = config.get('defragment_every', default=0)\n",
        "      if defrag_every and i % defrag_every == 0:\n",
        "        helpers.defragment()\n",
        "\n",
        "      if config.get('checkpoint_every') and i % config.checkpoint_every == 0:\n",
        "        saved_path = checkpoints.save_checkpoint(\n",
        "            ckpt_dir=work_unit_dir,\n",
        "            target={\n",
        "                'state': flax.jax_utils.unreplicate(state),\n",
        "                'vars': helpers.state_to_variables(state),\n",
        "                'origin': np.array(scene_origin.value),\n",
        "            },\n",
        "            step=l,\n",
        "            keep=1,\n",
        "            overwrite=True,\n",
        "            keep_every_n_steps=config.get('keep_every_n_steps', None))\n",
        "        logging.info('saved checkpoint to %s', saved_path)"
      ],
      "metadata": {
        "id": "OSEhye7OwP4l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NN3LHPaYORI"
      },
      "source": [
        "# Visualization helpers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zx7bGgCFwKgB"
      },
      "outputs": [],
      "source": [
        "def show_videos(work_unit_dir, title):\n",
        "  video_iters = config.iters\n",
        "  fps = config.lq_video_n_frames / 2\n",
        "  media.show_video(onp.concatenate([\n",
        "      media.read_video(os.path.join(work_unit_dir, f'frames_rgb_{video_iters:05d}.mp4')),\n",
        "      media.read_video(os.path.join(work_unit_dir, f'frames_acc_{video_iters:05d}.mp4')),\n",
        "      media.read_video(os.path.join(work_unit_dir, f'frames_depth_{video_iters:05d}.mp4')),\n",
        "  ], axis=2), title=title, fps=fps)\n",
        "\n",
        "\n",
        "def plot_losses(losses, log_interval=1):\n",
        "  steps = np.arange(len(losses['loss'])) * log_interval\n",
        "\n",
        "  keys = {\n",
        "    'loss': 'Total loss',\n",
        "    'clip_loss': 'CLIP negative cosine sim',\n",
        "    'grad_norm': 'Gradient norm',\n",
        "    'acc_mean': 'Avg transmittance',\n",
        "    'origin_norm': 'Origin drift',\n",
        "    'learning_rate': 'Learning rate',\n",
        "  }\n",
        "\n",
        "  _, axes = plt.subplots(1, len(keys), figsize=(len(losses) * 3, 3))\n",
        "  for i, (key, label) in enumerate(keys.items()):\n",
        "    axes[i].set_title(label)\n",
        "    values = onp.array(losses[key])\n",
        "    if key == 'acc_mean':\n",
        "      values = 1 - values  # Opacity to transmittance\n",
        "    axes[i].plot(steps, values)\n",
        "    if key in ('grad_norm', 'learning_rate'):\n",
        "      axes[i].set_yscale('log')\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def show_image_row(augs):\n",
        "  A, H, W, C = augs.shape\n",
        "  augs = augs.transpose(1, 0, 2, 3)\n",
        "  augs = augs.reshape((H, A*W, C))\n",
        "\n",
        "  plt.figure(figsize=(8*A, 8))\n",
        "  plt.imshow(augs)\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def show_image_grid(images, ncol=8):\n",
        "  \"\"\"Plot a grid of images.\"\"\"\n",
        "  images_stacked = onp.array(images)\n",
        "  T = len(images)\n",
        "  nrow = int(onp.ceil(T / ncol))\n",
        "  H, W, C = images[0].shape\n",
        "  dtype = images[0].dtype\n",
        "\n",
        "  canvas = onp.zeros((H*nrow, W*ncol, C), dtype=dtype)\n",
        "  for i, image in enumerate(images):\n",
        "    row, col = i // ncol, i % ncol\n",
        "    canvas[row*H:row*H+H, col*W:col*W+W, :] = image\n",
        "\n",
        "  plt.figure(figsize=(2*ncol, 2*nrow))\n",
        "  plt.imshow(canvas)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kf3MJgJkGHjS"
      },
      "source": [
        "# Run training\n",
        "100-200 iterations may be required before the scene begins to fill with visible content.\n",
        "\n",
        "The above configuration should work with 15 GB of GPU memory (e.g. Tesla T4). **If you run out of memory, tweak the configuration options above.** For example, try:\n",
        "*   num_samples = 48\n",
        "*   n_local_aug = 3\n",
        "\n",
        "You can also try scaling up parameters like resolution and n_local_aug for improved quality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PrCmSqTIAor-"
      },
      "outputs": [],
      "source": [
        "if use_gpu:\n",
        "  # Monitor memory usage\n",
        "  !nvidia-smi\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.config.experimental.set_visible_devices([], 'GPU')\n",
        "\n",
        "model = DreamField(config)\n",
        "losses = defaultdict(list)\n",
        "images = []\n",
        "log_interval = 2\n",
        "for step, (loss, image, origin, lr) in enumerate(model.run_train(\n",
        "    experiment_dir=experiment_dir, work_unit_dir=work_unit_dir, rng=rng,\n",
        "    yield_results=True)):\n",
        "  \n",
        "  if step % log_interval == 0:\n",
        "    losses['origin_norm'].append(np.sqrt(np.sum(np.square(origin))))\n",
        "    for key, value in loss.items():\n",
        "      losses[key].append(value)\n",
        "    losses['learning_rate'].append(lr)\n",
        "\n",
        "  if step % 25 == 0:\n",
        "    clear_output(wait=True)\n",
        "    show_image_row(image[:4])  # display up to 4 current augs\n",
        "    plot_losses(losses, log_interval)\n",
        "\n",
        "    # Plot past renders\n",
        "    images.append(image[0])  # limit to 1 aug for history\n",
        "    show_image_grid(images)\n",
        "\n",
        "    if use_gpu:\n",
        "      # Monitor memory usage\n",
        "      !nvidia-smi\n",
        "\n",
        "    if step % 100 != 0:\n",
        "      # Remove last iter's render so we don't plot too much\n",
        "      images.pop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I1m7YNq4eu73"
      },
      "outputs": [],
      "source": [
        "show_videos(work_unit_dir, title=config.query)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "GgSvskIfJn9I",
        "AEj5tFx4Jmbh",
        "ZLjBuwrkGFkQ",
        "f3Gy03snwOmU",
        "5NN3LHPaYORI"
      ],
      "machine_shape": "hm",
      "name": "Zero Shot Text Guided Object Generation with Dream Fields, lower memory.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}