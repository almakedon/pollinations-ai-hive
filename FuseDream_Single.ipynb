{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FuseDream-Single.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CppIQlPhhwhs"
      },
      "source": [
        "# *FuseDream*: Training-Free Text-to-Image Generation with Improved CLIP+GAN Space Optimization.\n",
        "\n",
        "By Xingchao Liu (https://github.com/gnobitab/FuseDream). \n",
        "\n",
        "Following the commands in order to set up the environment and generate images with text queries using *FuseDream*.\n",
        "\n",
        "This Colab notebook is the single image version of *FuseDream*. *FuseDream-Composition* will be shared in another Colab notebook.\n",
        "\n",
        "A baseline method (BigSleep) was provided by https://twitter.com/advadnoun.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "VA1PHoJrRiK9"
      },
      "source": [
        "# @title Licensed under the MIT License\n",
        "\n",
        "# Copyright (c) 2021 Katherine Crowson\n",
        "\n",
        "# Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "# of this software and associated documentation files (the \"Software\"), to deal\n",
        "# in the Software without restriction, including without limitation the rights\n",
        "# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "# copies of the Software, and to permit persons to whom the Software is\n",
        "# furnished to do so, subject to the following conditions:\n",
        "\n",
        "# The above copyright notice and this permission notice shall be included in\n",
        "# all copies or substantial portions of the Software.\n",
        "\n",
        "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n",
        "# THE SOFTWARE.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkUfzT60ZZ9q"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSfISAhyPmyp"
      },
      "source": [
        "!git clone https://github.com/gnobitab/FuseDream.git\n",
        "!pip install ftfy regex tqdm numpy scipy h5py lpips==0.1.4\n",
        "!pip install git+https://github.com/openai/CLIP.git\n",
        "!pip install gdown\n",
        "!gdown 'https://drive.google.com/uc?id=17ymX6rhsgHDZw_g5XgAFW4xLSDocARCM'\n",
        "!gdown 'https://drive.google.com/uc?id=1sOZ9og9kJLsqMNhaDnPJgzVsBZQ1sjZ5'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhhdWrSxQhwg"
      },
      "source": [
        "!ls\n",
        "!cp biggan-256.pth FuseDream/BigGAN_utils/weights/\n",
        "!cp biggan-512.pth FuseDream/BigGAN_utils/weights/\n",
        "%cd FuseDream"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AXgGDr_K3NV"
      },
      "source": [
        "import torch\n",
        "from tqdm import tqdm\n",
        "from torchvision.transforms import Compose, Resize, CenterCrop, ToTensor, Normalize\n",
        "import torchvision\n",
        "import BigGAN_utils.utils as utils\n",
        "import clip\n",
        "import torch.nn.functional as F\n",
        "from DiffAugment_pytorch import DiffAugment\n",
        "import numpy as np\n",
        "from fusedream_utils import FuseDreamBaseGenerator, get_G, save_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1paKfbekkmz"
      },
      "source": [
        "### Setting up parameters\n",
        "1. SENTENCE: The query text for generating the image. Note: we find that putting a period '.' at the end of the sentence can boost the quality of the generated images, e.g., 'A photo of a blue dog.' generates better images than 'A photo of a blue dog'.\n",
        "2. INIT_ITERS: Controls the number of images used for initialization (M in the paper, and M = INIT_ITERS*10). Use the default number 1000 should work well.\n",
        "3. OPT_ITERS: Controls the number of iterations for optimizing the latent variables. Use the default number 1000 should work well.\n",
        "4. NUM_BASIS: Controls the number of basis images used in optimization (k in the paper). Choose from 5, 10, 15 should work well.\n",
        "5. MODEL: Currently please choose from 'biggan-256' and 'biggan-512'.\n",
        "6. SEED: Random seed. Choose an arbitrary integer you like."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utIHfdoejnJg"
      },
      "source": [
        "#@title Parameters\n",
        "SENTENCE = \"Photo of an authentic shaman making sushi\" #@param {type:\"string\"}\n",
        "INIT_ITERS =  1000#@param {type:\"number\"}\n",
        "OPT_ITERS = 1000#@param {type:\"number\"}\n",
        "NUM_BASIS = 5#@param {type:\"number\"}\n",
        "MODEL = \"biggan-256\" #@param [\"biggan-256\",\"biggan-512\"]\n",
        "SEED = 0#@param {type:\"number\"}\n",
        "\n",
        "import sys\n",
        "sys.argv = [''] ### workaround to deal with the argparse in Jupyter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXMSuW2EQWsd"
      },
      "source": [
        "### Generation: Click the 'run' button and the final generated image will be shown after the end of the algorithm\n",
        "utils.seed_rng(SEED) \n",
        "\n",
        "sentence = SENTENCE\n",
        "\n",
        "print('Generating:', sentence)\n",
        "if MODEL == \"biggan-256\":\n",
        "    G, config = get_G(256) \n",
        "elif MODEL == \"biggan-512\":\n",
        "    G, config = get_G(512) \n",
        "else:\n",
        "    raise Exception('Model not supported')\n",
        "generator = FuseDreamBaseGenerator(G, config, 10) \n",
        "z_cllt, y_cllt = generator.generate_basis(sentence, init_iters=INIT_ITERS, num_basis=NUM_BASIS)\n",
        "\n",
        "z_cllt_save = torch.cat(z_cllt).cpu().numpy()\n",
        "y_cllt_save = torch.cat(y_cllt).cpu().numpy()\n",
        "img, z, y = generator.optimize_clip_score(z_cllt, y_cllt, sentence, latent_noise=False, augment=True, opt_iters=OPT_ITERS, optimize_y=True)\n",
        "### Set latent_noise = True yields slightly higher AugCLIP score, but slightly lower image quality. We set it to False for dogs.\n",
        "score = generator.measureAugCLIP(z, y, sentence, augment=True, num_samples=20)\n",
        "print('AugCLIP score:', score)\n",
        "import os\n",
        "if not os.path.exists('./samples'):\n",
        "    os.mkdir('./samples')\n",
        "save_image(img, 'samples/fusedream_%s_seed_%d_score_%.4f.png'%(sentence, SEED, score))\n",
        "\n",
        "from IPython import display\n",
        "display.display(display.Image('samples/fusedream_%s_seed_%d_score_%.4f.png'%(sentence, SEED, score)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "hmVNixoBYosu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}