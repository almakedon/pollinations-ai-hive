{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pollinations/hive/blob/main/notebooks/3%20Audio-To-Video/1%20Lucid%20Sonic%20Dreams.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ekvKCcD7nWY"
      },
      "source": [
        "<img src=\"https://pollinations.ai/ipfs/QmTp8v31wrHt3mvdiTv5FkMVyh2MDhWdk45XT3ff28RuuC\" />\n",
        "\n",
        "\n",
        "Generate a music video from an audio file - the video moves with every sound and produces abstract art by travelling through the latent space of a StyleGAN. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "Lucid Sonic Dreams syncs GAN-generated visuals to music. By default, it uses [NVLabs StyleGAN2](https://github.com/NVlabs/stylegan2), with pre-trained models lifted from [Justin Pinkney's consolidated repository](https://github.com/justinpinkney/awesome-pretrained-stylegan2). Custom weights and other GAN architectures can be used as well.\n",
        "\n",
        "For a more detailed description of the technique refer to: [Introducing Lucid Sonic Dreams: Sync GAN Art to Music with a Few Lines of Python Code!](https://towardsdatascience.com/introducing-lucid-sonic-dreams-sync-gan-art-to-music-with-a-few-lines-of-python-code-b04f88722de1)\n",
        "\n",
        "Sample output can be found on [YouTube](https://youtu.be/l-nGC-ve7sI) and [Instagram](https://www.instagram.com/lucidsonicdreams/).\n",
        "\n",
        "**[UPD 17.10.2021]** Exposed more parameters\n",
        "[UPD 1.10.2021] Added Visionary Art Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "E50DZCnE7rEa"
      },
      "outputs": [],
      "source": [
        "# Input audio file (wav or mp3)\n",
        "audio_file = '' #@param {type: \"string\"}\n",
        "\n",
        "# The style to use\n",
        "style = \"Visionary Art\"  #@param [\"Abstract art\",\"Anime portraits\",\"CIFAR 10\",\"CIFAR 100\",\"Doors\",\"Imagenet\",\"Maps\",\"Visionary Art\",\"WikiArt\",\"beetles\",\"cakes\",\"car (config-e)\",\"car (config-f)\",\"cat\",\"church\",\"faces (FFHQ config-e 256x256)\",\"faces (FFHQ config-e)\",\"faces (FFHQ config-f 512x512)\",\"faces (FFHQ config-f)\",\"faces (FFHQ slim 256x256)\",\"figure drawings\",\"flowers\",\"fursona\",\"grumpy cat\",\"horse\",\"microscope images\",\"modern art\",\"my little pony\",\"obama\",\"painting faces\",\"panda\",\"textures\",\"trypophobia\",\"ukiyoe faces\",\"wildlife\"]\n",
        "\n",
        "# Resolution of the generated video \n",
        "resolution = 512 #@param {type: \"integer\"}\n",
        "\n",
        "# Frames per second of generated video\n",
        "fps = 25 #@param {type: \"number\"}\n",
        "\n",
        "# The \"strength\" of the pulse. It is recommended to keep this between 0 and 100.\n",
        "pulse_react = 80 #@param {type: \"number\"}\n",
        "\n",
        "# Whether the pulse should react to percussive or harmonic elements\n",
        "pulse_react_to = \"percussive\" #@param [\"percussive\", \"harmonic\"]\n",
        "\n",
        "#  The \"strength\" of the motion. Between 0 and 100\n",
        "motion_react = 80 #@param {type: \"number\"}\n",
        "\n",
        "# Whether the motion should react to percussive or harmonic elements\n",
        "motion_react_to = \"harmonic\" #@param [\"harmonic\", \"percussive\"]\n",
        "\n",
        "# Degree of randomness of motion. Higher values will typically prevent the video from cycling through the same visuals repeatedly. Must range from 0 to 100.\n",
        "motion_randomness = 50 #@param {type: \"number\"}\n",
        "\n",
        "# Controls the variety of visuals generated. Lower values lead to lower variety. Note: A very low value will usually lead to \"jittery\" visuals. Must range from 0 to 100.\n",
        "truncation = 100 #@param {type: \"number\"}\n",
        "\n",
        "# Custom StyleGAN2 model file *(optional)*\n",
        "file_custom_model = '' #@param {type: \"string\"}\n",
        "\n",
        "# Load a FastGAN / Projected GAN model instead of StyleGAN2\n",
        "use_fastgan = False #@param {type: \"boolean\"}\n",
        "\n",
        "output_path = '/content'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if file_custom_model != '':\n",
        "    style = file_custom_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if use_fastgan:\n",
        "    \n",
        "    network_pkl = file_custom_model\n",
        "\n",
        "    %cd /content/\n",
        "\n",
        "    !git clone https://github.com/NVlabs/stylegan2-ada.git stylegan2\n",
        "    !cp -rv stylegan2/dnnlib .\n",
        "    import sys\n",
        "    sys.path.append(\"/content/stylegan2\")\n",
        "\n",
        "    %cd /content\n",
        "    !git clone https://github.com/autonomousvision/projected_gan\n",
        "    !pip install timm dill\n",
        "    import sys\n",
        "    sys.path.append(\"/content/projected_gan\")\n",
        "    # Copyright (c) 2021, NVIDIA CORPORATION & AFFILIATES.  All rights reserved.\n",
        "    #\n",
        "    # NVIDIA CORPORATION and its licensors retain all intellectual property\n",
        "    # and proprietary rights in and to this software, related documentation\n",
        "    # and any modifications thereto.  Any use, reproduction, disclosure or\n",
        "    # distribution of this software and related documentation without an express\n",
        "    # license agreement from NVIDIA CORPORATION is strictly prohibited.\n",
        "\n",
        "    \"\"\"Generate images using pretrained network pickle.\"\"\"\n",
        "\n",
        "    import os\n",
        "    import re\n",
        "    from typing import List, Optional, Tuple, Union\n",
        "\n",
        "    import click\n",
        "    import dnnlib\n",
        "    import numpy as np\n",
        "    import PIL.Image\n",
        "    import torch\n",
        "\n",
        "    import legacy\n",
        "\n",
        "    #----------------------------------------------------------------------------\n",
        "\n",
        "    def parse_range(s: Union[str, List]) -> List[int]:\n",
        "        '''Parse a comma separated list of numbers or ranges and return a list of ints.\n",
        "        Example: '1,2,5-10' returns [1, 2, 5, 6, 7]\n",
        "        '''\n",
        "        if isinstance(s, list): return s\n",
        "        ranges = []\n",
        "        range_re = re.compile(r'^(\\d+)-(\\d+)$')\n",
        "        for p in s.split(','):\n",
        "            m = range_re.match(p)\n",
        "            if m:\n",
        "                ranges.extend(range(int(m.group(1)), int(m.group(2))+1))\n",
        "            else:\n",
        "                ranges.append(int(p))\n",
        "        return ranges\n",
        "\n",
        "    #----------------------------------------------------------------------------\n",
        "\n",
        "    def parse_vec2(s: Union[str, Tuple[float, float]]) -> Tuple[float, float]:\n",
        "        '''Parse a floating point 2-vector of syntax 'a,b'.\n",
        "        Example:\n",
        "            '0,1' returns (0,1)\n",
        "        '''\n",
        "        if isinstance(s, tuple): return s\n",
        "        parts = s.split(',')\n",
        "        if len(parts) == 2:\n",
        "            return (float(parts[0]), float(parts[1]))\n",
        "        raise ValueError(f'cannot parse 2-vector {s}')\n",
        "\n",
        "    #----------------------------------------------------------------------------\n",
        "\n",
        "    def make_transform(translate: Tuple[float,float], angle: float):\n",
        "        m = np.eye(3)\n",
        "        s = np.sin(angle/360.0*np.pi*2)\n",
        "        c = np.cos(angle/360.0*np.pi*2)\n",
        "        m[0][0] = c\n",
        "        m[0][1] = s\n",
        "        m[0][2] = translate[0]\n",
        "        m[1][0] = -s\n",
        "        m[1][1] = c\n",
        "        m[1][2] = translate[1]\n",
        "        return m\n",
        "\n",
        "    #----------------------------------------------------------------------------\n",
        "    # \"/content/drive/MyDrive/sam/projected gan training/training-runs/00000-fastgan-sofia512-gpus1-batch64-/network-snapshot.pkl\",\n",
        "    # [1,2,3], \n",
        "    # 1,\n",
        "    # \"const\", \n",
        "    # \"/content\",\n",
        "    # (0,0), \n",
        "    # 0, \n",
        "    #  None)\n",
        "\n",
        "    print('Loading networks from \"%s\"...' % network_pkl)\n",
        "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "    with dnnlib.util.open_url(network_pkl) as f:\n",
        "        G = legacy.load_network_pkl(f)['G_ema'].to(device) # type: ignore\n",
        "\n",
        "    noise_dim = G.z_dim\n",
        "\n",
        "    def generate_images(\n",
        "        G,\n",
        "        z,\n",
        "        truncation_psi: float,\n",
        "        noise_mode: str,\n",
        "        translate: Tuple[float,float],\n",
        "        rotate: float,\n",
        "        class_idx: Optional[int]\n",
        "    ):\n",
        "        \"\"\"Generate images using pretrained network pickle.\n",
        "        Examples:\n",
        "        \\b\n",
        "        # Generate an image using pre-trained AFHQv2 model (\"Ours\" in Figure 1, left).\n",
        "        python gen_images.py --outdir=out --trunc=1 --seeds=2 \\\\\n",
        "            --network=https://api.ngc.nvidia.com/v2/models/nvidia/research/stylegan3/versions/1/files/stylegan3-r-afhqv2-512x512.pkl\n",
        "        \\b\n",
        "        # Generate uncurated images with truncation using the MetFaces-U dataset\n",
        "        python gen_images.py --outdir=out --trunc=0.7 --seeds=600-605 \\\\\n",
        "            --network=https://api.ngc.nvidia.com/v2/models/nvidia/research/stylegan3/versions/1/files/stylegan3-t-metfacesu-1024x1024.pkl\n",
        "        \"\"\"\n",
        "\n",
        "        # Labels.\n",
        "        label = torch.zeros([1, G.c_dim], device=device)\n",
        "        if G.c_dim != 0:\n",
        "            if class_idx is None:\n",
        "                raise click.ClickException('Must specify class label with --class when using a conditional network')\n",
        "            label[:, class_idx] = 1\n",
        "        else:\n",
        "            if class_idx is not None:\n",
        "                print ('warn: --class=lbl ignored when running on an unconditional network')\n",
        "\n",
        "        # Generate images.\n",
        "        #for seed_idx, seed in enumerate(seeds):\n",
        "\n",
        "        # Construct an inverse rotation/translation matrix and pass to the generator.  The\n",
        "        # generator expects this matrix as an inverse to avoid potentially failing numerical\n",
        "        # operations in the network.\n",
        "        if hasattr(G.synthesis, 'input'):\n",
        "            m = make_transform(translate, rotate)\n",
        "            m = np.linalg.inv(m)\n",
        "            G.synthesis.input.transform.copy_(torch.from_numpy(m))\n",
        "\n",
        "        img = G(z, label, truncation_psi=truncation_psi, noise_mode=noise_mode)\n",
        "        img = (img.permute(0, 2, 3, 1) * 127.5 + 128).clamp(0, 255).to(torch.uint8)\n",
        "        return PIL.Image.fromarray(img[0].cpu().numpy(), 'RGB')\n",
        "\n",
        "\n",
        "    def projected_gan(noise_batch, class_batch):\n",
        "        noise_tensor = torch.from_numpy(noise_batch).cuda().float()\n",
        "        return [generate_images(G, noise_tensor, 1, \"const\", (0,0), 0, None)]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSBBXrcy1ssE"
      },
      "source": [
        "# A. Set-Up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kBYttBTtlho"
      },
      "source": [
        "## A.1. Set-up GPU\n",
        "\n",
        "Navigate to **Runtime -> Change runtime type** and make sure **Hardware accelerator** is set to GPU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PByrKtjcuMP8"
      },
      "source": [
        "## A.3. Install Lucid Sonic Dreams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50buTzTKOf6x",
        "outputId": "1be217ba-6b34-4dde-aed5-d2ea1721e20b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting lucidsonicdreams\n",
            "  Downloading lucidsonicdreams-0.4.tar.gz (11 kB)\n",
            "Collecting tensorflow==1.15\n",
            "  Downloading tensorflow-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (412.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3 MB 21 kB/s \n",
            "\u001b[?25hRequirement already satisfied: librosa in /usr/local/lib/python3.7/dist-packages (from lucidsonicdreams) (0.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from lucidsonicdreams) (1.19.5)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.7/dist-packages (from lucidsonicdreams) (0.2.3.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from lucidsonicdreams) (7.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from lucidsonicdreams) (4.62.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from lucidsonicdreams) (1.4.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from lucidsonicdreams) (0.16.2)\n",
            "Collecting pygit2\n",
            "  Downloading pygit2-1.6.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.6 MB 60.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (from lucidsonicdreams) (3.6.4)\n",
            "Collecting mega.py\n",
            "  Downloading mega.py-1.0.8-py2.py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from lucidsonicdreams) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from lucidsonicdreams) (1.1.5)\n",
            "Requirement already satisfied: SoundFile in /usr/local/lib/python3.7/dist-packages (from lucidsonicdreams) (0.10.3.post1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15->lucidsonicdreams) (3.17.3)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
            "\u001b[K     |████████████████████████████████| 503 kB 73.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15->lucidsonicdreams) (3.3.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15->lucidsonicdreams) (0.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15->lucidsonicdreams) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15->lucidsonicdreams) (1.41.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15->lucidsonicdreams) (1.12.1)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 66.5 MB/s \n",
            "\u001b[?25hCollecting keras-applications>=1.0.8\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 9.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15->lucidsonicdreams) (1.15.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15->lucidsonicdreams) (0.8.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15->lucidsonicdreams) (0.12.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15->lucidsonicdreams) (1.1.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15->lucidsonicdreams) (0.37.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15->lucidsonicdreams) (3.1.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15->lucidsonicdreams) (57.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15->lucidsonicdreams) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15->lucidsonicdreams) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15->lucidsonicdreams) (4.8.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow==1.15->lucidsonicdreams) (1.5.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15->lucidsonicdreams) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15->lucidsonicdreams) (3.7.4.3)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa->lucidsonicdreams) (0.22.2.post1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa->lucidsonicdreams) (1.5.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa->lucidsonicdreams) (21.0)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa->lucidsonicdreams) (4.4.2)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa->lucidsonicdreams) (2.1.9)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa->lucidsonicdreams) (1.0.1)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa->lucidsonicdreams) (0.51.2)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa->lucidsonicdreams) (0.2.2)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa->lucidsonicdreams) (0.34.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->librosa->lucidsonicdreams) (2.4.7)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa->lucidsonicdreams) (1.4.4)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from SoundFile->lucidsonicdreams) (1.14.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->SoundFile->lucidsonicdreams) (2.20)\n",
            "Collecting tenacity<6.0.0,>=5.1.5\n",
            "  Downloading tenacity-5.1.5-py2.py3-none-any.whl (34 kB)\n",
            "Collecting pycryptodome<4.0.0,>=3.9.6\n",
            "  Downloading pycryptodome-3.10.4-cp35-abi3-manylinux2010_x86_64.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 53.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pathlib==1.0.1 in /usr/local/lib/python3.7/dist-packages (from mega.py->lucidsonicdreams) (1.0.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->lucidsonicdreams) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->lucidsonicdreams) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->lucidsonicdreams) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->lucidsonicdreams) (1.24.3)\n",
            "Requirement already satisfied: imageio<3.0,>=2.1.2 in /usr/local/lib/python3.7/dist-packages (from moviepy->lucidsonicdreams) (2.4.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->lucidsonicdreams) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->lucidsonicdreams) (2.8.2)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->lucidsonicdreams) (3.2.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->lucidsonicdreams) (2.6.3)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->lucidsonicdreams) (1.1.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->lucidsonicdreams) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->lucidsonicdreams) (0.10.0)\n",
            "Building wheels for collected packages: lucidsonicdreams, gast\n",
            "  Building wheel for lucidsonicdreams (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lucidsonicdreams: filename=lucidsonicdreams-0.4-py3-none-any.whl size=11498 sha256=d2b23e84f603f10570cd789418255823781cdcc95b8967c6e805c4f84ae1534f\n",
            "  Stored in directory: /root/.cache/pip/wheels/18/23/3e/f6f4265bde5ac9993ce077083c570dd06032867ae0aadd3481\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=c3da4a8d5d533d757edf8c149ded2997aafec283a762b94634ea54260fbcafab\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
            "Successfully built lucidsonicdreams gast\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, tenacity, pycryptodome, keras-applications, gast, tensorflow, pygit2, mega.py, lucidsonicdreams\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.6.0\n",
            "    Uninstalling tensorflow-estimator-2.6.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.6.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.6.0\n",
            "    Uninstalling tensorboard-2.6.0:\n",
            "      Successfully uninstalled tensorboard-2.6.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.4.0\n",
            "    Uninstalling gast-0.4.0:\n",
            "      Successfully uninstalled gast-0.4.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.6.0\n",
            "    Uninstalling tensorflow-2.6.0:\n",
            "      Successfully uninstalled tensorflow-2.6.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-probability 0.14.1 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\n",
            "kapre 0.3.5 requires tensorflow>=2.0.0, but you have tensorflow 1.15.0 which is incompatible.\u001b[0m\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 lucidsonicdreams-0.4 mega.py-1.0.8 pycryptodome-3.10.4 pygit2-1.6.1 tenacity-5.1.5 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n"
          ]
        }
      ],
      "source": [
        "!pip install lucidsonicdreams\n",
        "\n",
        "model_file = f\"{style}.pkl\"\n",
        "\n",
        "!wget -N \"https://pollinations.ai/ipfs/QmV5HQM1Ms3c6sejmsMwiCDNLhMLNs6f8jESenDvcYjfin/{model_file}\"\n",
        "\n",
        "!ffmpeg -y -i \"{audio_file}\" -vn -acodec pcm_s16le /tmp/audio.wav\n",
        "audio_file = '/tmp/audio.wav'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63dO9FBu1Mv0"
      },
      "source": [
        "# B. Generate Sample Videos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AgAsUB54ej8"
      },
      "source": [
        "## B.1. Choosing a Style\n",
        "\n",
        "Styles can be selected using the **style** parameter, which takes in any of the following:\n",
        "\n",
        "*   A valid default style name provided by the package. Run **show_styles()** to print valid values. *Note: These styles are loaded from [this repository](https://github.com/justinpinkney/awesome-pretrained-stylegan2) by Justin Pinkney.*\n",
        "\n",
        "*   A path to a .pkl file that contains pre-trained StyleGAN weights\n",
        "\n",
        "*   A custom function that takes noise_batch and class_batch parameters and outputs a list of Pillow Images (see example in **B.5**)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNnHbJgB2EWk"
      },
      "source": [
        "## B.2. Using Default Settings\n",
        "\n",
        "This package is set-up so that the only arguments required are the **file path to your audio track** and the **file name of the video output**. This code snippet outputs a 45-second, low-resolution preview of a video using the \"modern art\" style, and all the other default settings.\n",
        "\n",
        "The song used here is **Chemical Love by Basically Saturday Night**. You can watch the official music video [here](https://youtu.be/Gi7oQrtyjKI), or listen to them on [Spotify](https://open.spotify.com/artist/46tGdhXAQbTvxVOGgy0Fqu?si=E8mUjbWbR2uiiMR2MUc_4w)!\n",
        "\n",
        "Click [here](https://youtu.be/oGXfOmqFYTg) to view a full-length sample video without having to run the code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z7DkKcO9cfM_"
      },
      "outputs": [],
      "source": [
        "from lucidsonicdreams import LucidSonicDream\n",
        "\n",
        "pulse_percussive = pulse_react_to == \"percussive\"\n",
        "pulse_harmonic = pulse_react_to == \"harmonic\"\n",
        "\n",
        "motion_percussive = motion_react_to == \"percussive\"\n",
        "motion_harmonic =  motion_react_to == \"harmonic\"\n",
        "\n",
        "if use_fastgan:\n",
        "    L = LucidSonicDream(song = audio_file,\n",
        "                        style = projected_gan, \n",
        "                        input_shape = noise_dim,\n",
        "                        num_possible_classes = 0)\n",
        "else:   \n",
        "    L = LucidSonicDream(song = audio_file,\n",
        "                        style = model_file)\n",
        "\n",
        "L.hallucinate(file_name = 'output.mp4',\n",
        "              resolution = resolution,\n",
        "              fps = fps,\n",
        "              motion_percussive = motion_percussive,\n",
        "              motion_harmonic = motion_harmonic,\n",
        "              pulse_percussive = pulse_percussive,\n",
        "              pulse_harmonic = pulse_harmonic,\n",
        "              pulse_react = pulse_react / 200,\n",
        "              motion_react = motion_react / 200,\n",
        "              motion_randomness = motion_randomness / 100,\n",
        "              truncation = truncation / 100\n",
        "              )\n",
        "!cp output.mp4 $output_path/output.mp4\n",
        "#files.download(\"chemical_love.mp4\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os.path\n",
        "if not os.path.exists(output_path+'/output.mp4'):\n",
        "  raise Exception(\"Expected output file does not exist.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "Audio-To-Video - Lucid Sonic Dreams ",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
