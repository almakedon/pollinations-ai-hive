{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAw2262ARz1Y"
      },
      "source": [
        "<img src=\"https://pollinations-ipfs-gateway.zencraft.studio/ipfs/QmRb3oe5v5WhHGHTV1aDmMzsbqZLn7wKZnduHu1wZk7iGE?filename=output_1.png\" width=\"300\" height=\"auto\" />\n",
        "Prompt: *Pollinations*\n",
        "\n",
        "Доступные ресурсы by russian company [Sber](https://github.com/sberbank-ai/ru-dalle).\n",
        "\n",
        "With added translation step. You should be able to input any language.\n",
        "\n",
        "[UPD 2.11.2021] Tweaked parameters slightly according to discord user lurkwot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "DRR-MpnHRvZ-"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Text Prompt. Can be any language.\n",
        "text_input = 'cyberpunk fairie'  #@param {type: \"string\"}´\n",
        "\n",
        "output_path = \"/content\"\n",
        "\n",
        "social = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "RXHbpMh1QlWd"
      },
      "outputs": [],
      "source": [
        "#@title Доступные ресурсы\n",
        "\n",
        "\n",
        "if social:\n",
        "    text_input = text_input + \"|christmas:1|text:-0.5\"\n",
        "\n",
        "    \n",
        "import multiprocessing\n",
        "import torch\n",
        "from psutil import virtual_memory\n",
        "\n",
        "ram_gb = round(virtual_memory().total / 1024**3, 1)\n",
        "\n",
        "print('CPU:', multiprocessing.cpu_count())\n",
        "print('RAM GB:', ram_gb)\n",
        "print(\"PyTorch version:\", torch.__version__)\n",
        "print(\"CUDA version:\", torch.version.cuda)\n",
        "print(\"cuDNN version:\", torch.backends.cudnn.version())\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"device:\", device.type)\n",
        "\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7UJXhzngQOVT"
      },
      "outputs": [],
      "source": [
        "!pip install translators --upgrade\n",
        "import translators as ts\n",
        "\n",
        "def to_russian(text):\n",
        "  return ts.google(text, to_language=\"ru\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "my3y3ORmQpYU"
      },
      "outputs": [],
      "source": [
        "!pip install rudalle==0.0.1rc4 > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mFBMm0cVRV-E"
      },
      "outputs": [],
      "source": [
        "from rudalle.pipelines import generate_images, show, super_resolution, cherry_pick_by_clip\n",
        "from rudalle import get_rudalle_model, get_tokenizer, get_vae, get_realesrgan, get_ruclip\n",
        "from rudalle.utils import seed_everything"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kwzWV3I7SB3g"
      },
      "outputs": [],
      "source": [
        "device = 'cuda'\n",
        "dalle = get_rudalle_model('Malevich', pretrained=True, fp16=True, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DFpu82HiSB7u"
      },
      "outputs": [],
      "source": [
        "realesrgan = get_realesrgan('x4', device=device)\n",
        "tokenizer = get_tokenizer()\n",
        "vae = get_vae().to(device)\n",
        "ruclip, ruclip_processor = get_ruclip('ruclip-vit-base-patch32-v5')\n",
        "ruclip = ruclip.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7x02MYpdYZ-5"
      },
      "source": [
        "## generation by ruDALLE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GdOYJvwZSB-D"
      },
      "outputs": [],
      "source": [
        "text = to_russian(text_input)\n",
        "pil_images = []\n",
        "scores = []\n",
        "\n",
        "#seed_everything(42)\n",
        "\n",
        "for top_k, top_p, images_num in [\n",
        "    (2048, .99, 2)\n",
        "]:\n",
        "    _pil_images, _scores = generate_images(text, tokenizer, dalle, vae, top_k=top_k, images_num=images_num, top_p=top_p)\n",
        "    pil_images += _pil_images\n",
        "    scores += _scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UA4sY-ZCSCA7"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVjTQ3JPYilA"
      },
      "source": [
        "### auto-cherry-pick by ruCLIP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZI2y4KEYma5"
      },
      "source": [
        "## super resolution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P-sfSSBzQpar"
      },
      "outputs": [],
      "source": [
        "sr_images = super_resolution(pil_images, realesrgan)\n",
        "for i,image in enumerate(sr_images):\n",
        "  image.save(f\"{output_path}/output_{i}.png\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Доступные ресурсы - Russian DALL-E",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
