{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pollinations/hive/blob/main/interesting_notebooks/Projected%20Lucid%20Sonic%20Dreams.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ekvKCcD7nWY"
      },
      "source": [
        "<img src=\"https://pollinations.ai/ipfs/QmTp8v31wrHt3mvdiTv5FkMVyh2MDhWdk45XT3ff28RuuC\" />\n",
        "\n",
        "\n",
        "Generate a music video from an audio file - the video moves with every sound and produces abstract art by travelling through the latent space of a StyleGAN. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GR2-ZxixP6R3"
      },
      "source": [
        "\n",
        "Lucid Sonic Dreams syncs GAN-generated visuals to music. By default, it uses [NVLabs StyleGAN2](https://github.com/NVlabs/stylegan2), with pre-trained models lifted from [Justin Pinkney's consolidated repository](https://github.com/justinpinkney/awesome-pretrained-stylegan2). Custom weights and other GAN architectures can be used as well.\n",
        "\n",
        "For a more detailed description of the technique refer to: [Introducing Lucid Sonic Dreams: Sync GAN Art to Music with a Few Lines of Python Code!](https://towardsdatascience.com/introducing-lucid-sonic-dreams-sync-gan-art-to-music-with-a-few-lines-of-python-code-b04f88722de1)\n",
        "\n",
        "Sample output can be found on [YouTube](https://youtu.be/l-nGC-ve7sI) and [Instagram](https://www.instagram.com/lucidsonicdreams/).\n",
        "\n",
        "**[UPD 17.10.2021]** Exposed more parameters\n",
        "[UPD 1.10.2021] Added Visionary Art Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "E50DZCnE7rEa"
      },
      "outputs": [],
      "source": [
        "# Input audio file (wav or mp3)\n",
        "audio_file = '/content/elektrobank.mp3' #@param {type: \"string\"}\n",
        "\n",
        "# The style to use\n",
        "style = None\n",
        "\n",
        "network_pkl = \"/content/drive/MyDrive/sam/projected gan training/training-runs/00001-fastgan-sofia512-gpus1-batch32-/network-snapshot.pkl\" #@param {type: \"string\"}\n",
        "\n",
        "# Resolution of the generated video \n",
        "resolution = 512 #@param {type: \"integer\"}\n",
        "\n",
        "# Frames per second of generated video\n",
        "fps = 25 #@param {type: \"number\"}\n",
        "\n",
        "# The \"strength\" of the pulse. It is recommended to keep this between 0 and 100.\n",
        "pulse_react = 50 #@param {type: \"number\"}\n",
        "\n",
        "# Whether the pulse should react to percussive or harmonic elements\n",
        "pulse_react_to = \"percussive\" #@param [\"percussive\", \"harmonic\"]\n",
        "\n",
        "#  The \"strength\" of the motion. Between 0 and 100\n",
        "motion_react = 50 #@param {type: \"number\"}\n",
        "\n",
        "# Whether the motion should react to percussive or harmonic elements\n",
        "motion_react_to = \"harmonic\" #@param [\"harmonic\", \"percussive\"]\n",
        "\n",
        "# Degree of randomness of motion. Higher values will typically prevent the video from cycling through the same visuals repeatedly. Must range from 0 to 100.\n",
        "motion_randomness = 50 #@param {type: \"number\"}\n",
        "\n",
        "# Controls the variety of visuals generated. Lower values lead to lower variety. Note: A very low value will usually lead to \"jittery\" visuals. Must range from 0 to 100.\n",
        "truncation = 100 #@param {type: \"number\"}\n",
        "\n",
        "output_path = '/content'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSBBXrcy1ssE"
      },
      "source": [
        "# A. Set-Up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kBYttBTtlho"
      },
      "source": [
        "## A.1. Set-up GPU\n",
        "\n",
        "Navigate to **Runtime -> Change runtime type** and make sure **Hardware accelerator** is set to GPU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PByrKtjcuMP8"
      },
      "source": [
        "## A.3. Install Lucid Sonic Dreams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50buTzTKOf6x",
        "outputId": "b9a6728d-8237-412a-ed16-5bdf9bce50f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lucidsonicdreams in /usr/local/lib/python3.7/dist-packages (0.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from lucidsonicdreams) (1.3.5)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.7/dist-packages (from lucidsonicdreams) (0.2.3.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from lucidsonicdreams) (2.23.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from lucidsonicdreams) (7.1.2)\n",
            "Requirement already satisfied: pygit2 in /usr/local/lib/python3.7/dist-packages (from lucidsonicdreams) (1.9.0)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (from lucidsonicdreams) (4.2.2)\n",
            "Requirement already satisfied: mega.py in /usr/local/lib/python3.7/dist-packages (from lucidsonicdreams) (1.0.8)\n",
            "Requirement already satisfied: tensorflow==1.15 in /usr/local/lib/python3.7/dist-packages (from lucidsonicdreams) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from lucidsonicdreams) (1.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from lucidsonicdreams) (1.4.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from lucidsonicdreams) (4.63.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from lucidsonicdreams) (0.18.3)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.7/dist-packages (from lucidsonicdreams) (0.8.1)\n",
            "Requirement already satisfied: SoundFile in /usr/local/lib/python3.7/dist-packages (from lucidsonicdreams) (0.10.3.post1)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15->lucidsonicdreams) (1.15.1)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15->lucidsonicdreams) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15->lucidsonicdreams) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15->lucidsonicdreams) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15->lucidsonicdreams) (1.1.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15->lucidsonicdreams) (0.2.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15->lucidsonicdreams) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15->lucidsonicdreams) (0.37.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15->lucidsonicdreams) (0.8.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15->lucidsonicdreams) (3.17.3)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15->lucidsonicdreams) (1.0.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15->lucidsonicdreams) (0.2.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15->lucidsonicdreams) (1.13.3)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15->lucidsonicdreams) (1.44.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15->lucidsonicdreams) (3.3.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15->lucidsonicdreams) (3.1.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15->lucidsonicdreams) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15->lucidsonicdreams) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15->lucidsonicdreams) (3.3.6)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15->lucidsonicdreams) (4.11.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15->lucidsonicdreams) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15->lucidsonicdreams) (3.7.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown->lucidsonicdreams) (4.6.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown->lucidsonicdreams) (3.6.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow==1.15->lucidsonicdreams) (1.5.2)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa->lucidsonicdreams) (0.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa->lucidsonicdreams) (1.1.0)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa->lucidsonicdreams) (0.51.2)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa->lucidsonicdreams) (2.1.9)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa->lucidsonicdreams) (4.4.2)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa->lucidsonicdreams) (1.0.2)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa->lucidsonicdreams) (1.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa->lucidsonicdreams) (21.3)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa->lucidsonicdreams) (0.34.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->librosa->lucidsonicdreams) (3.0.7)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa->lucidsonicdreams) (1.4.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->lucidsonicdreams) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->lucidsonicdreams) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->lucidsonicdreams) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->lucidsonicdreams) (2.10)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa->lucidsonicdreams) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from SoundFile->lucidsonicdreams) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->SoundFile->lucidsonicdreams) (2.21)\n",
            "Requirement already satisfied: pycryptodome<4.0.0,>=3.9.6 in /usr/local/lib/python3.7/dist-packages (from mega.py->lucidsonicdreams) (3.14.1)\n",
            "Requirement already satisfied: pathlib==1.0.1 in /usr/local/lib/python3.7/dist-packages (from mega.py->lucidsonicdreams) (1.0.1)\n",
            "Requirement already satisfied: tenacity<6.0.0,>=5.1.5 in /usr/local/lib/python3.7/dist-packages (from mega.py->lucidsonicdreams) (5.1.5)\n",
            "Requirement already satisfied: imageio<3.0,>=2.1.2 in /usr/local/lib/python3.7/dist-packages (from moviepy->lucidsonicdreams) (2.4.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->lucidsonicdreams) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->lucidsonicdreams) (2.8.2)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests->lucidsonicdreams) (1.7.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->lucidsonicdreams) (2.6.3)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->lucidsonicdreams) (3.2.2)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image->lucidsonicdreams) (2021.11.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->lucidsonicdreams) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->lucidsonicdreams) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->lucidsonicdreams) (1.3.2)\n",
            "Access denied with the following error:\n",
            "\n",
            " \tCannot retrieve the public link of the file. You may need to change\n",
            "\tthe permission to 'Anyone with the link', or have had many accesses. \n",
            "\n",
            "You may still be able to access the file from the browser:\n",
            "\n",
            "\t https://drive.google.com/uc?id=19hNptJSXji_9h7DMJBVlEMe-izWXvkYQ \n",
            "\n",
            "ffmpeg version 3.4.8-0ubuntu0.2 Copyright (c) 2000-2020 the FFmpeg developers\n",
            "  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.2 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
            "  libavutil      55. 78.100 / 55. 78.100\n",
            "  libavcodec     57.107.100 / 57.107.100\n",
            "  libavformat    57. 83.100 / 57. 83.100\n",
            "  libavdevice    57. 10.100 / 57. 10.100\n",
            "  libavfilter     6.107.100 /  6.107.100\n",
            "  libavresample   3.  7.  0 /  3.  7.  0\n",
            "  libswscale      4.  8.100 /  4.  8.100\n",
            "  libswresample   2.  9.100 /  2.  9.100\n",
            "  libpostproc    54.  7.100 / 54.  7.100\n",
            "Input #0, mp3, from '/content/elektrobank.mp3':\n",
            "  Metadata:\n",
            "    major_brand     : dash\n",
            "    minor_version   : 0\n",
            "    compatible_brands: iso6mp41\n",
            "    encoder         : Lavf59.6.100\n",
            "  Duration: 00:05:47.82, start: 0.025057, bitrate: 192 kb/s\n",
            "    Stream #0:0: Audio: mp3, 44100 Hz, stereo, s16p, 192 kb/s\n",
            "    Metadata:\n",
            "      encoder         : Lavc59.12\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (mp3 (native) -> pcm_s16le (native))\n",
            "Press [q] to stop, [?] for help\n",
            "Output #0, wav, to '/tmp/audio.wav':\n",
            "  Metadata:\n",
            "    major_brand     : dash\n",
            "    minor_version   : 0\n",
            "    compatible_brands: iso6mp41\n",
            "    ISFT            : Lavf57.83.100\n",
            "    Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 44100 Hz, stereo, s16, 1411 kb/s\n",
            "    Metadata:\n",
            "      encoder         : Lavc57.107.100 pcm_s16le\n",
            "size=   59912kB time=00:05:47.78 bitrate=1411.2kbits/s speed= 282x    \n",
            "video:0kB audio:59912kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.000127%\n"
          ]
        }
      ],
      "source": [
        "!pip install lucidsonicdreams\n",
        "\n",
        "if style=='VisionaryArt.pkl':\n",
        "    !gdown --id 19hNptJSXji_9h7DMJBVlEMe-izWXvkYQ\n",
        "\n",
        "if style=='tron.pkl':\n",
        "    !wget -N https://pollinations.ai/ipfs/QmQ4BxDwBJPwXMvitGJM2NmfVxA2GorqNpx5gqET1cFRod/tron.pkl\n",
        "\n",
        "!ffmpeg -y -i \"{audio_file}\" -vn -acodec pcm_s16le /tmp/audio.wav\n",
        "audio_file = '/tmp/audio.wav'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63dO9FBu1Mv0"
      },
      "source": [
        "# B. Generate Sample Videos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AgAsUB54ej8"
      },
      "source": [
        "## B.1. Choosing a Style\n",
        "\n",
        "Styles can be selected using the **style** parameter, which takes in any of the following:\n",
        "\n",
        "*   A valid default style name provided by the package. Run **show_styles()** to print valid values. *Note: These styles are loaded from [this repository](https://github.com/justinpinkney/awesome-pretrained-stylegan2) by Justin Pinkney.*\n",
        "\n",
        "*   A path to a .pkl file that contains pre-trained StyleGAN weights\n",
        "\n",
        "*   A custom function that takes noise_batch and class_batch parameters and outputs a list of Pillow Images (see example in **B.5**)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNnHbJgB2EWk"
      },
      "source": [
        "## B.2. Using Default Settings\n",
        "\n",
        "This package is set-up so that the only arguments required are the **file path to your audio track** and the **file name of the video output**. This code snippet outputs a 45-second, low-resolution preview of a video using the \"modern art\" style, and all the other default settings.\n",
        "\n",
        "The song used here is **Chemical Love by Basically Saturday Night**. You can watch the official music video [here](https://youtu.be/Gi7oQrtyjKI), or listen to them on [Spotify](https://open.spotify.com/artist/46tGdhXAQbTvxVOGgy0Fqu?si=E8mUjbWbR2uiiMR2MUc_4w)!\n",
        "\n",
        "Click [here](https://youtu.be/oGXfOmqFYTg) to view a full-length sample video without having to run the code."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "XJ2doB2qWp8h",
        "outputId": "5c35c57d-b702-48dd-f70e-652f2d9630b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/autonomousvision/projected_gan\n",
        "!pip install timm dill\n",
        "%cd /content/projected_gan\n",
        "# Copyright (c) 2021, NVIDIA CORPORATION & AFFILIATES.  All rights reserved.\n",
        "#\n",
        "# NVIDIA CORPORATION and its licensors retain all intellectual property\n",
        "# and proprietary rights in and to this software, related documentation\n",
        "# and any modifications thereto.  Any use, reproduction, disclosure or\n",
        "# distribution of this software and related documentation without an express\n",
        "# license agreement from NVIDIA CORPORATION is strictly prohibited.\n",
        "\n",
        "\"\"\"Generate images using pretrained network pickle.\"\"\"\n",
        "\n",
        "import os\n",
        "import re\n",
        "from typing import List, Optional, Tuple, Union\n",
        "\n",
        "import click\n",
        "import dnnlib\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "import torch\n",
        "\n",
        "import legacy\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "\n",
        "def parse_range(s: Union[str, List]) -> List[int]:\n",
        "    '''Parse a comma separated list of numbers or ranges and return a list of ints.\n",
        "    Example: '1,2,5-10' returns [1, 2, 5, 6, 7]\n",
        "    '''\n",
        "    if isinstance(s, list): return s\n",
        "    ranges = []\n",
        "    range_re = re.compile(r'^(\\d+)-(\\d+)$')\n",
        "    for p in s.split(','):\n",
        "        m = range_re.match(p)\n",
        "        if m:\n",
        "            ranges.extend(range(int(m.group(1)), int(m.group(2))+1))\n",
        "        else:\n",
        "            ranges.append(int(p))\n",
        "    return ranges\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "\n",
        "def parse_vec2(s: Union[str, Tuple[float, float]]) -> Tuple[float, float]:\n",
        "    '''Parse a floating point 2-vector of syntax 'a,b'.\n",
        "    Example:\n",
        "        '0,1' returns (0,1)\n",
        "    '''\n",
        "    if isinstance(s, tuple): return s\n",
        "    parts = s.split(',')\n",
        "    if len(parts) == 2:\n",
        "        return (float(parts[0]), float(parts[1]))\n",
        "    raise ValueError(f'cannot parse 2-vector {s}')\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "\n",
        "def make_transform(translate: Tuple[float,float], angle: float):\n",
        "    m = np.eye(3)\n",
        "    s = np.sin(angle/360.0*np.pi*2)\n",
        "    c = np.cos(angle/360.0*np.pi*2)\n",
        "    m[0][0] = c\n",
        "    m[0][1] = s\n",
        "    m[0][2] = translate[0]\n",
        "    m[1][0] = -s\n",
        "    m[1][1] = c\n",
        "    m[1][2] = translate[1]\n",
        "    return m\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "# \"/content/drive/MyDrive/sam/projected gan training/training-runs/00000-fastgan-sofia512-gpus1-batch64-/network-snapshot.pkl\",\n",
        "# [1,2,3], \n",
        "# 1,\n",
        "# \"const\", \n",
        "# \"/content\",\n",
        "# (0,0), \n",
        "# 0, \n",
        "#  None)\n",
        "\n",
        "print('Loading networks from \"%s\"...' % network_pkl)\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "with dnnlib.util.open_url(network_pkl) as f:\n",
        "    G = legacy.load_network_pkl(f)['G_ema'].to(device) # type: ignore\n",
        "\n",
        "noise_dim = G.z_dim\n",
        "\n",
        "def generate_images(\n",
        "    G,\n",
        "    z,\n",
        "    truncation_psi: float,\n",
        "    noise_mode: str,\n",
        "    translate: Tuple[float,float],\n",
        "    rotate: float,\n",
        "    class_idx: Optional[int]\n",
        "):\n",
        "    \"\"\"Generate images using pretrained network pickle.\n",
        "    Examples:\n",
        "    \\b\n",
        "    # Generate an image using pre-trained AFHQv2 model (\"Ours\" in Figure 1, left).\n",
        "    python gen_images.py --outdir=out --trunc=1 --seeds=2 \\\\\n",
        "        --network=https://api.ngc.nvidia.com/v2/models/nvidia/research/stylegan3/versions/1/files/stylegan3-r-afhqv2-512x512.pkl\n",
        "    \\b\n",
        "    # Generate uncurated images with truncation using the MetFaces-U dataset\n",
        "    python gen_images.py --outdir=out --trunc=0.7 --seeds=600-605 \\\\\n",
        "        --network=https://api.ngc.nvidia.com/v2/models/nvidia/research/stylegan3/versions/1/files/stylegan3-t-metfacesu-1024x1024.pkl\n",
        "    \"\"\"\n",
        "\n",
        "    # Labels.\n",
        "    label = torch.zeros([1, G.c_dim], device=device)\n",
        "    if G.c_dim != 0:\n",
        "        if class_idx is None:\n",
        "            raise click.ClickException('Must specify class label with --class when using a conditional network')\n",
        "        label[:, class_idx] = 1\n",
        "    else:\n",
        "        if class_idx is not None:\n",
        "            print ('warn: --class=lbl ignored when running on an unconditional network')\n",
        "\n",
        "    # Generate images.\n",
        "    #for seed_idx, seed in enumerate(seeds):\n",
        "\n",
        "    # Construct an inverse rotation/translation matrix and pass to the generator.  The\n",
        "    # generator expects this matrix as an inverse to avoid potentially failing numerical\n",
        "    # operations in the network.\n",
        "    if hasattr(G.synthesis, 'input'):\n",
        "        m = make_transform(translate, rotate)\n",
        "        m = np.linalg.inv(m)\n",
        "        G.synthesis.input.transform.copy_(torch.from_numpy(m))\n",
        "\n",
        "    img = G(z, label, truncation_psi=truncation_psi, noise_mode=noise_mode)\n",
        "    img = (img.permute(0, 2, 3, 1) * 127.5 + 128).clamp(0, 255).to(torch.uint8)\n",
        "    return PIL.Image.fromarray(img[0].cpu().numpy(), 'RGB')\n",
        "\n"
      ],
      "metadata": {
        "id": "eDzQHdZzVjA2",
        "outputId": "ff237e9e-b468-490e-dbc6-591106d52dda",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "fatal: destination path 'projected_gan' already exists and is not an empty directory.\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.7/dist-packages (0.5.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (0.3.4)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.11.1+cu111)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (3.10.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.21.5)\n",
            "/content/projected_gan\n",
            "Loading networks from \"/content/drive/MyDrive/sam/projected gan training/training-runs/00001-fastgan-sofia512-gpus1-batch32-/network-snapshot.pkl\"...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#z = torch.from_numpy(np.random.RandomState(123).randn(1, G.z_dim)).to(device).float()\n",
        "\n",
        "\n",
        "#print(generate_images(G,z, 1,\"const\", (0,0), 0, None))"
      ],
      "metadata": {
        "id": "zMM3s50hYFxB",
        "outputId": "b3ad97ed-113c-47b1-a41a-a5a9fe7d08ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FAD792F5D90>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def projected_gan(noise_batch, class_batch):\n",
        "  noise_tensor = torch.from_numpy(noise_batch).cuda().float()\n",
        "  return [generate_images(G, noise_tensor, 1, \"const\", (0,0), 0, None)]"
      ],
      "metadata": {
        "id": "Mb4csn99eU3Q"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "id": "twcGEbTjh0kq",
        "outputId": "e864295b-6bfa-48a4-dbe3-dafd9c9a6d13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/stylegan2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z7DkKcO9cfM_",
        "outputId": "4e412d29-215d-4213-bfd8-e44aac765366",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/stylegan2\n",
            "Preparing style...\n",
            "Preparing audio...\n",
            "Loading effects...\n",
            "\n",
            "\n",
            "Doing math...\n",
            "\n",
            "\n",
            "\n",
            "Hallucinating... \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 47%|████▋     | 4330/9218 [11:17<12:21,  6.59it/s]"
          ]
        }
      ],
      "source": [
        "%cd /content/stylegan2\n",
        "import sys\n",
        "sys.path.append(\"/content/stylegan2\")\n",
        "\n",
        "from lucidsonicdreams import LucidSonicDream\n",
        "\n",
        "pulse_percussive = pulse_react_to == \"percussive\"\n",
        "pulse_harmonic = pulse_react_to == \"harmonic\"\n",
        "\n",
        "motion_percussive = motion_react_to == \"percussive\"\n",
        "motion_harmonic =  motion_react_to == \"harmonic\"\n",
        "\n",
        "L = LucidSonicDream(song = audio_file,\n",
        "                    style = projected_gan, \n",
        "                    input_shape = noise_dim,\n",
        "                    num_possible_classes = 0)\n",
        "\n",
        "\n",
        "\n",
        "L.hallucinate(file_name = 'output.mp4',\n",
        "              resolution = resolution,\n",
        "              fps = fps,\n",
        "              motion_percussive = motion_percussive,\n",
        "              motion_harmonic = motion_harmonic,\n",
        "              pulse_percussive = pulse_percussive,\n",
        "              pulse_harmonic = pulse_harmonic,\n",
        "              pulse_react = pulse_react / 200,\n",
        "              motion_react = motion_react / 200,\n",
        "              motion_randomness = motion_randomness / 100,\n",
        "              truncation = truncation / 100\n",
        "              )\n",
        "!cp output.mp4 $output_path/output.mp4\n",
        "#files.download(\"chemical_love.mp4\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "n4LnKv5ghns3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Audio-To-Video - Lucid Sonic Dreams ",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}