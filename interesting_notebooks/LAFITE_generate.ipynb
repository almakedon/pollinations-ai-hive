{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pollinations/hive/blob/main/interesting_notebooks/LAFITE_generate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_input = 'an armchair in the shape of an avocado' #@param {type: \"string\"}\n",
        "\n",
        "num_images_to_generate = 3 #@param {type: \"number\"}"
      ],
      "metadata": {
        "id": "-gEIFvghrONM"
      },
      "id": "-gEIFvghrONM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SL53VpxnPuBD",
        "outputId": "4ae56732-5c82-4d7a-9046-da95c1a2495f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torch==1.9.1\n",
            "  Using cached torch-1.9.1-cp37-cp37m-manylinux1_x86_64.whl (831.4 MB)\n",
            "Collecting torchtext==0.10.1\n",
            "  Using cached torchtext-0.10.1-cp37-cp37m-manylinux1_x86_64.whl (7.6 MB)\n",
            "Collecting torchvision==0.10.1\n",
            "  Using cached torchvision-0.10.1-cp37-cp37m-manylinux1_x86_64.whl (22.1 MB)\n",
            "Collecting torchaudio==0.10.1\n",
            "  Using cached torchaudio-0.10.1-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.1) (3.10.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.1) (1.21.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.1) (4.63.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.1) (2.23.0)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.1) (7.1.2)\n",
            "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of torchtext to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of <Python from Requires-Python> to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of torch to determine which version is compatible with other requirements. This could take a while.\n",
            "\u001b[31mERROR: Cannot install torch==1.9.1, torchaudio==0.10.1, torchtext==0.10.1 and torchvision==0.10.1 because these package versions have conflicting dependencies.\u001b[0m\n",
            "\n",
            "The conflict is caused by:\n",
            "    The user requested torch==1.9.1\n",
            "    torchtext 0.10.1 depends on torch==1.9.1\n",
            "    torchvision 0.10.1 depends on torch==1.9.1\n",
            "    torchaudio 0.10.1 depends on torch==1.10.1\n",
            "\n",
            "To fix this you could try to:\n",
            "1. loosen the range of package versions you've specified\n",
            "2. remove package versions to allow pip attempt to solve the dependency conflict\n",
            "\n",
            "\u001b[31mERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/user_guide/#fixing-conflicting-dependencies\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install torch==1.9.1 torchtext==0.10.1 torchvision==0.10.1 torchaudio==0.10.1\n",
        "%cd /content\n",
        "!git clone https://github.com/drboog/Lafite\n",
        "%cd /content/Lafite\n",
        "!pip install git+https://github.com/openai/CLIP.git\n",
        "!pip install ninja"
      ],
      "id": "SL53VpxnPuBD"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttxH-sBXO_7l",
        "outputId": "e3dad4fb-eefd-4e22-8d87-5dea5816c66e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-28 13:17:09--  https://public-ipfs-gateway.pollinations.ai/ipfs/Qmdt4rch9AHveSh9JohEHqUGFMdfThsXJknwHjtQUQJQhe/pre-trained-google-cc-best-fid.pkl\n",
            "Resolving public-ipfs-gateway.pollinations.ai (public-ipfs-gateway.pollinations.ai)... 65.108.44.19\n",
            "Connecting to public-ipfs-gateway.pollinations.ai (public-ipfs-gateway.pollinations.ai)|65.108.44.19|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 478149328 (456M) [application/octet-stream]\n",
            "Saving to: ‘pre-trained-google-cc-best-fid.pkl’\n",
            "\n",
            "pre-trained-google- 100%[===================>] 456.00M  2.35MB/s    in 1m 42s  \n",
            "\n",
            "2022-03-28 13:18:53 (4.48 MB/s) - ‘pre-trained-google-cc-best-fid.pkl’ saved [478149328/478149328]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -N https://public-ipfs-gateway.pollinations.ai/ipfs/Qmdt4rch9AHveSh9JohEHqUGFMdfThsXJknwHjtQUQJQhe/pre-trained-google-cc-best-fid.pkl"
      ],
      "id": "ttxH-sBXO_7l"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6fa9c631",
        "outputId": "de1170b8-cc0a-4f51-deaf-ba6930dfda81"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-86ac8e7df5ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpathlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mdnnlib\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlegacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'dnnlib'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pickle\n",
        "import os\n",
        "import clip\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import dnnlib, legacy\n",
        "import clip\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as T\n",
        "from tqdm import tqdm\n",
        "import scipy"
      ],
      "id": "6fa9c631"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b93b1f9c"
      },
      "outputs": [],
      "source": [
        "class Generator:\n",
        "    def __init__(self, device, path):\n",
        "        self.name = 'generator'\n",
        "        self.model = self.load_model(device, path)\n",
        "        self.device = device\n",
        "        self.force_32 = False\n",
        "        \n",
        "    def load_model(self, device, path):\n",
        "        with dnnlib.util.open_url(path) as f:\n",
        "            network= legacy.load_network_pkl(f)\n",
        "            self.G_ema = network['G_ema'].to(device)\n",
        "            self.D = network['D'].to(device)\n",
        "#                 self.G = network['G'].to(device)\n",
        "            return self.G_ema\n",
        "        \n",
        "    def generate(self, z, c, fts, noise_mode='const', return_styles=True):\n",
        "        return self.model(z, c, fts=fts, noise_mode=noise_mode, return_styles=return_styles, force_fp32=self.force_32)\n",
        "    \n",
        "    def generate_from_style(self, style, noise_mode='const'):\n",
        "        ws = torch.randn(1, self.model.num_ws, 512)\n",
        "        return self.model.synthesis(ws, fts=None, styles=style, noise_mode=noise_mode, force_fp32=self.force_32)\n",
        "    \n",
        "    def tensor_to_img(self, tensor):\n",
        "        img = torch.clamp((tensor + 1.) * 127.5, 0., 255.)\n",
        "        img_list = img.permute(0, 2, 3, 1)\n",
        "        img_list = [img for img in img_list]\n",
        "        return Image.fromarray(torch.cat(img_list, dim=-2).detach().cpu().numpy().astype(np.uint8))"
      ],
      "id": "b93b1f9c"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "29873681"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "\n",
        "    device = 'cuda:0' # please use GPU, do not use CPU\n",
        "    path = '/content/Lafite/pre-trained-google-cc-best-fid.pkl'  # pre-trained model\n",
        "    generator = Generator(device=device, path=path)\n",
        "    clip_model, _ = clip.load(\"ViT-B/32\", device=device)\n",
        "    clip_model = clip_model.eval()\n",
        "    \n",
        "    \n",
        "    tokenized_text = clip.tokenize([text_input]*num_images_to_generate).to(device)\n",
        "    txt_fts = clip_model.encode_text(tokenized_text)\n",
        "    txt_fts = txt_fts/txt_fts.norm(dim=-1, keepdim=True)\n",
        "    \n",
        "    z = torch.randn((num_images_to_generate, 512)).to(device)\n",
        "    c = torch.randn((num_images_to_generate, 1)).to(device) # label is actually not used\n",
        "    img, _ = generator.generate(z=z, c=c, fts=txt_fts)\n",
        "    to_show_img = generator.tensor_to_img(img)\n",
        "    to_show_img.save('./generated.jpg')\n"
      ],
      "id": "29873681"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "LAFITE - generate.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}