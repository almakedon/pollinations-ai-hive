{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pollinations/hive/blob/main/interesting_notebooks/LAFITE_generate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttxH-sBXO_7l",
        "outputId": "e89a0862-1e0c-4ff3-df17-6b9472107c48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n",
            "fatal: destination path 'Lafite' already exists and is not an empty directory.\n",
            "/content/Lafite\n",
            "Collecting git+https://github.com/openai/CLIP.git\n",
            "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-slhkye99\n",
            "  Running command git clone -q https://github.com/openai/CLIP.git /tmp/pip-req-build-slhkye99\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (6.1.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (2019.12.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (4.63.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (0.11.1+cu111)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from ftfy->clip==1.0) (0.2.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->clip==1.0) (3.10.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->clip==1.0) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->clip==1.0) (1.21.5)\n",
            "Collecting ninja\n",
            "  Downloading ninja-1.10.2.3-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (108 kB)\n",
            "\u001b[K     |████████████████████████████████| 108 kB 10.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: ninja\n",
            "Successfully installed ninja-1.10.2.3\n"
          ]
        }
      ],
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/drboog/Lafite\n",
        "%cd /content/Lafite\n",
        "!pip install git+https://github.com/openai/CLIP.git\n",
        "!pip install ninja"
      ],
      "id": "ttxH-sBXO_7l"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SL53VpxnPuBD",
        "outputId": "4ae56732-5c82-4d7a-9046-da95c1a2495f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torch==1.9.1\n",
            "  Using cached torch-1.9.1-cp37-cp37m-manylinux1_x86_64.whl (831.4 MB)\n",
            "Collecting torchtext==0.10.1\n",
            "  Using cached torchtext-0.10.1-cp37-cp37m-manylinux1_x86_64.whl (7.6 MB)\n",
            "Collecting torchvision==0.10.1\n",
            "  Using cached torchvision-0.10.1-cp37-cp37m-manylinux1_x86_64.whl (22.1 MB)\n",
            "Collecting torchaudio==0.10.1\n",
            "  Using cached torchaudio-0.10.1-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.1) (3.10.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.1) (1.21.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.1) (4.63.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.1) (2.23.0)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.1) (7.1.2)\n",
            "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of torchtext to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of <Python from Requires-Python> to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of torch to determine which version is compatible with other requirements. This could take a while.\n",
            "\u001b[31mERROR: Cannot install torch==1.9.1, torchaudio==0.10.1, torchtext==0.10.1 and torchvision==0.10.1 because these package versions have conflicting dependencies.\u001b[0m\n",
            "\n",
            "The conflict is caused by:\n",
            "    The user requested torch==1.9.1\n",
            "    torchtext 0.10.1 depends on torch==1.9.1\n",
            "    torchvision 0.10.1 depends on torch==1.9.1\n",
            "    torchaudio 0.10.1 depends on torch==1.10.1\n",
            "\n",
            "To fix this you could try to:\n",
            "1. loosen the range of package versions you've specified\n",
            "2. remove package versions to allow pip attempt to solve the dependency conflict\n",
            "\n",
            "\u001b[31mERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/user_guide/#fixing-conflicting-dependencies\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install torch==1.9.1 torchtext==0.10.1 torchvision==0.10.1 torchaudio==0.10.1\n",
        " "
      ],
      "id": "SL53VpxnPuBD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zVRfFtGpQ6LK"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "id": "zVRfFtGpQ6LK"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6fa9c631",
        "outputId": "24e9727f-e46c-435d-e6ba-1968b94b1ab0"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-86ac8e7df5ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpathlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mdnnlib\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlegacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'dnnlib'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pickle\n",
        "import os\n",
        "import clip\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import dnnlib, legacy\n",
        "import clip\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as T\n",
        "from tqdm import tqdm\n",
        "import scipy"
      ],
      "id": "6fa9c631"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b93b1f9c"
      },
      "outputs": [],
      "source": [
        "class Generator:\n",
        "    def __init__(self, device, path):\n",
        "        self.name = 'generator'\n",
        "        self.model = self.load_model(device, path)\n",
        "        self.device = device\n",
        "        self.force_32 = False\n",
        "        \n",
        "    def load_model(self, device, path):\n",
        "        with dnnlib.util.open_url(path) as f:\n",
        "            network= legacy.load_network_pkl(f)\n",
        "            self.G_ema = network['G_ema'].to(device)\n",
        "            self.D = network['D'].to(device)\n",
        "#                 self.G = network['G'].to(device)\n",
        "            return self.G_ema\n",
        "        \n",
        "    def generate(self, z, c, fts, noise_mode='const', return_styles=True):\n",
        "        return self.model(z, c, fts=fts, noise_mode=noise_mode, return_styles=return_styles, force_fp32=self.force_32)\n",
        "    \n",
        "    def generate_from_style(self, style, noise_mode='const'):\n",
        "        ws = torch.randn(1, self.model.num_ws, 512)\n",
        "        return self.model.synthesis(ws, fts=None, styles=style, noise_mode=noise_mode, force_fp32=self.force_32)\n",
        "    \n",
        "    def tensor_to_img(self, tensor):\n",
        "        img = torch.clamp((tensor + 1.) * 127.5, 0., 255.)\n",
        "        img_list = img.permute(0, 2, 3, 1)\n",
        "        img_list = [img for img in img_list]\n",
        "        return Image.fromarray(torch.cat(img_list, dim=-2).detach().cpu().numpy().astype(np.uint8))"
      ],
      "id": "b93b1f9c"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "29873681"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "\n",
        "    device = 'cuda:0' # please use GPU, do not use CPU\n",
        "    path = '/content/COCO2014_Language-free_Gaussian.pkl'  # pre-trained model\n",
        "    generator = Generator(device=device, path=path)\n",
        "    clip_model, _ = clip.load(\"ViT-B/32\", device=device)\n",
        "    clip_model = clip_model.eval()\n",
        "    \n",
        "    txt = 'an armchair in the shape of an avocado'  # input sentence\n",
        "    tokenized_text = clip.tokenize([txt]).to(device)\n",
        "    txt_fts = clip_model.encode_text(tokenized_text)\n",
        "    txt_fts = txt_fts/txt_fts.norm(dim=-1, keepdim=True)\n",
        "    \n",
        "    z = torch.randn((1, 512)).to(device)\n",
        "    c = torch.randn((1, 1)).to(device) # label is actually not used\n",
        "    img, _ = generator.generate(z=z, c=c, fts=txt_fts)\n",
        "    to_show_img = generator.tensor_to_img(img)\n",
        "    to_show_img.save('./generated.jpg')\n"
      ],
      "id": "29873681"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "LAFITE - generate.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}